{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmEwKf8zXUqY"
   },
   "source": [
    "#  SkimLit\n",
    "\n",
    "The purpose of this notebook is to build an NLP model to make reading medical abstracts easier.\n",
    "\n",
    "The paper we are replicating (the source of the dataset that we'll be using) is available here : https://arxiv.org/abs/1710.06071\n",
    "\n",
    "If you want to find the ground truth for this notebook (with lots of diagrams and text annotations) see the GitHib: https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/09_SkimLit_nlp_milestone_project_2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIA4rECtgecj"
   },
   "source": [
    " ## Get data\n",
    "\n",
    " Since we'll be replicating the paper above ( PubMed 200k RCT), lets download the dataset they used\n",
    "\n",
    " We can do so from the authors Github: https://github.com/Franck-Dernoncourt/pubmed-rct\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v2vEOjnAh-m_",
    "outputId": "097eab58-49f7-4f45-f366-52129ea034a7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'pubmed-rct'...\n",
      "Updating files:  76% (10/13)\n",
      "Updating files:  84% (11/13)\n",
      "Updating files:  92% (12/13)\n",
      "Updating files: 100% (13/13)\n",
      "Updating files: 100% (13/13), done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is B2AA-FBB6\n",
      "\n",
      " Directory of C:\\Users\\a\\Documents\\GitHub\\SkimLit\\pubmed-rct\n",
      "\n",
      "10-12-2021  15:52    <DIR>          .\n",
      "10-12-2021  15:52    <DIR>          ..\n",
      "10-12-2021  15:52    <DIR>          PubMed_200k_RCT\n",
      "10-12-2021  15:52    <DIR>          PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
      "10-12-2021  15:52    <DIR>          PubMed_20k_RCT\n",
      "10-12-2021  15:52    <DIR>          PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
      "10-12-2021  15:52             2,403 README.md\n",
      "               1 File(s)          2,403 bytes\n",
      "               6 Dir(s)  440,236,290,048 bytes free\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct\n",
    "%ls pubmed-rct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0BUrogUwiEtk",
    "outputId": "a55bcfa5-447c-4732-ddbd-422aadb0d58d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is B2AA-FBB6\n",
      "\n",
      " Directory of C:\\Users\\a\\Documents\\GitHub\\SkimLit\\pubmed-rct\\PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
      "\n",
      "10-12-2021  15:52    <DIR>          .\n",
      "10-12-2021  15:52    <DIR>          ..\n",
      "10-12-2021  15:52         4,880,409 dev.txt\n",
      "10-12-2021  15:52         4,846,504 test.txt\n",
      "10-12-2021  15:52        29,118,832 train.txt\n",
      "               3 File(s)     38,845,745 bytes\n",
      "               2 Dir(s)  440,243,896,320 bytes free\n"
     ]
    }
   ],
   "source": [
    "# Check what files are in the PubMed_20K dataset\n",
    "# %ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
    "\n",
    "%ls \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RJIyH-gDiXR9"
   },
   "outputs": [],
   "source": [
    "# Start our experiments using the 20K dataset with numbers replaced by '@' sign\n",
    "data_dir = 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2KUc43n6jUNJ",
    "outputId": "8c4b335a-3540-4f5e-d8e9-d2ea8c9df9c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
       " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
       " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all of the filenames in the target directory\n",
    "import os\n",
    "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vrGreLnckLJV"
   },
   "source": [
    "## Preprocess data\n",
    "\n",
    "Now we've got some text data, its time to become one with it.\n",
    "\n",
    "And one of the best ways to become one with the data is to ...\n",
    "> Visualize, Visualize, Visualize\n",
    "\n",
    "So with that in mind, lets write a function to read in all of the lines of a target tesx file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0nBVK8u7lTtM"
   },
   "outputs": [],
   "source": [
    "# Create function to read the lines of a document\n",
    "\n",
    "def get_lines(filenames):\n",
    "    \"\"\"\n",
    "    Reads filename (a text file) and returns the lines of text as a list.\n",
    "    \n",
    "    Args:\n",
    "        filename: a string containing the target filepath to read.\n",
    "    \n",
    "    Returns:\n",
    "        A list of strings with one string per line from the target filename.\n",
    "        For example:\n",
    "        [\"this is the first line of filename\",\n",
    "        \"this is the second line of filename\",\n",
    "        \"...\"]\n",
    "    \"\"\"\n",
    "\n",
    "    with open(filenames,'r') as f:\n",
    "      return f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5npjdy5ml1Oj",
    "outputId": "aeecb492-7f1e-4b6a-f80f-031d1b418b51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['###24293578\\n',\n",
       " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
       " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
       " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
       " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
       " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
       " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
       " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
       " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
       " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
       " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
       " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
       " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
       " '\\n',\n",
       " '###24854809\\n',\n",
       " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
       " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
       " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
       " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
       " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets read in the training lines\n",
    "train_lines = get_lines(data_dir+\"train.txt\")\n",
    "train_lines[:20] # the whole first example of an abstract + a little more of the next one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUTPXB8mmoF4",
    "outputId": "29095ab3-c1a3-44a8-c94a-3101e16df9ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210040"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hD241wB7nPrc"
   },
   "source": [
    "Lets think how we want our data to look...\n",
    "\n",
    "How I think our data would be best represented\n",
    "\n",
    "```\n",
    "[{'line_number': 0,\n",
    "  'target': 'OBJECTIVE',\n",
    "  'text': \"to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .\",\n",
    "  'total_lines': 11},\n",
    "  ...]\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e68GeieNn_0c"
   },
   "source": [
    "Lets write a function which turns each of our datasets into the above format so we can continue to prepare our data for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WCLvsrKZtG_Z"
   },
   "outputs": [],
   "source": [
    "def preprocess_text_with_line_numbers(filename):\n",
    "  \"\"\"Returns a list of dictionaries of abstract line data.\n",
    "\n",
    "  Takes in filename, reads its contents and sorts through each line,\n",
    "  extracting things like the target label, the text of the sentence,\n",
    "  how many sentences are in the current abstract and what sentence number\n",
    "  the target line is.\n",
    "\n",
    "  Args:\n",
    "      filename: a string of the target text file to read and extract line data\n",
    "      from.\n",
    "\n",
    "  Returns:\n",
    "      A list of dictionaries each containing a line from an abstract,\n",
    "      the lines label, the lines position in the abstract and the total number\n",
    "      of lines in the abstract where the line is from. For example:\n",
    "\n",
    "      [{\"target\": 'CONCLUSION',\n",
    "        \"text\": The study couldn't have gone better, turns out people are kinder than you think\",\n",
    "        \"line_number\": 8,\n",
    "        \"total_lines\": 8}]\n",
    "  \"\"\"\n",
    "\n",
    "  input_lines = get_lines(filename)\n",
    "  abstract_lines = \"\" # create an empty abstract\n",
    "  abstract_samples = [] # create an empty list of abstracts\n",
    "\n",
    "  # Loop through each line in target file\n",
    "  for line in input_lines:\n",
    "    if line.startswith('###'): # check to see if line is an ID line\n",
    "      abstract_id = line\n",
    "      abstract_lines = \"\" # reset abstract string if the line is an id line\n",
    "\n",
    "    elif line.isspace(): # Check to see if line is a new line\n",
    "      abstract_line_split = abstract_lines.splitlines() # split abstract into separate lines\n",
    "\n",
    "\n",
    "      # Iterate through each line in abstract and count them at the same time\n",
    "\n",
    "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
    "        line_data = {} # Create an empty dictionary for each line\n",
    "        target_text_split = abstract_line.split(\"\\t\") # split target label from text\n",
    "        line_data[\"target\"] = target_text_split[0] # get target label\n",
    "        line_data[\"text\"] = target_text_split[1].lower() # get target text and lower it\n",
    "        line_data[\"line_number\"] = abstract_line_number # what number line does the line appear in the abstract?\n",
    "        line_data[\"total_lines\"] = len(abstract_line_split) - 1 # how many total lines are in the abstract? (start from 0)\n",
    "        abstract_samples.append(line_data) # add line data to abstract samples list\n",
    "\n",
    "\n",
    "    else: # if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
    "      abstract_lines += line\n",
    "\n",
    "  return abstract_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ShAgHC5Tz-eQ",
    "outputId": "56bd8535-9aa9-47ad-ef1f-edcea31ba254"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "180040 30212 30135\n"
     ]
    }
   ],
   "source": [
    "# Get data from file and preprocess it\n",
    "\n",
    "## %%time shows the time duration of the cell\n",
    "%time\n",
    "train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n",
    "val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\")\n",
    "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
    "print(len(train_samples), len(val_samples), len(test_samples))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-eluu-KY1JsX",
    "outputId": "ae34c813-9c16-4c5f-c029-b6b42c4ea6a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': 'OBJECTIVE',\n",
       "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       "  'line_number': 0,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       "  'line_number': 1,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       "  'line_number': 2,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       "  'line_number': 3,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
       "  'line_number': 4,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
       "  'line_number': 5,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
       "  'line_number': 6,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
       "  'line_number': 7,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
       "  'line_number': 8,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'these differences remained significant at @ weeks .',\n",
       "  'line_number': 9,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
       "  'line_number': 10,\n",
       "  'total_lines': 11},\n",
       " {'target': 'CONCLUSIONS',\n",
       "  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
       "  'line_number': 11,\n",
       "  'total_lines': 11},\n",
       " {'target': 'BACKGROUND',\n",
       "  'text': 'emotional eating is associated with overeating and the development of obesity .',\n",
       "  'line_number': 0,\n",
       "  'total_lines': 10},\n",
       " {'target': 'BACKGROUND',\n",
       "  'text': 'yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .',\n",
       "  'line_number': 1,\n",
       "  'total_lines': 10}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first abstract of our training data\n",
    "train_samples[:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCwMfC8b2CFD"
   },
   "source": [
    "Now that our data is the format of a list of dictionaries, how about we turn it into a DataFrame to further visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "ufpIuJ2A3Lcl",
    "outputId": "affe4b8b-2732-48a2-a1ea-12b2e385ae30"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>line_number</th>\n",
       "      <th>total_lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>a total of @ patients with primary knee oa wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>outcome measures included pain reduction and i...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>pain was assessed using the visual analog pain...</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>secondary outcome measures included the wester...</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>there was a clinically relevant reduction in t...</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>the mean difference between treatment arms ( @...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>further , there was a clinically relevant redu...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>these differences remained significant at @ we...</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>the outcome measures in rheumatology clinical ...</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CONCLUSIONS</td>\n",
       "      <td>low-dose oral prednisolone had both a short-te...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>emotional eating is associated with overeating...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>yet , empirical evidence for individual ( trai...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                                               text  \\\n",
       "0     OBJECTIVE  to investigate the efficacy of @ weeks of dail...   \n",
       "1       METHODS  a total of @ patients with primary knee oa wer...   \n",
       "2       METHODS  outcome measures included pain reduction and i...   \n",
       "3       METHODS  pain was assessed using the visual analog pain...   \n",
       "4       METHODS  secondary outcome measures included the wester...   \n",
       "5       METHODS  serum levels of interleukin @ ( il-@ ) , il-@ ...   \n",
       "6       RESULTS  there was a clinically relevant reduction in t...   \n",
       "7       RESULTS  the mean difference between treatment arms ( @...   \n",
       "8       RESULTS  further , there was a clinically relevant redu...   \n",
       "9       RESULTS  these differences remained significant at @ we...   \n",
       "10      RESULTS  the outcome measures in rheumatology clinical ...   \n",
       "11  CONCLUSIONS  low-dose oral prednisolone had both a short-te...   \n",
       "12   BACKGROUND  emotional eating is associated with overeating...   \n",
       "13   BACKGROUND  yet , empirical evidence for individual ( trai...   \n",
       "\n",
       "    line_number  total_lines  \n",
       "0             0           11  \n",
       "1             1           11  \n",
       "2             2           11  \n",
       "3             3           11  \n",
       "4             4           11  \n",
       "5             5           11  \n",
       "6             6           11  \n",
       "7             7           11  \n",
       "8             8           11  \n",
       "9             9           11  \n",
       "10           10           11  \n",
       "11           11           11  \n",
       "12            0           10  \n",
       "13            1           10  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.DataFrame(train_samples)\n",
    "val_df = pd.DataFrame(val_samples)\n",
    "test_df = pd.DataFrame(test_samples)\n",
    "train_df.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Yq-pk2T3hfo",
    "outputId": "99248765-15cb-4083-8f96-6e7c6f0faeb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "METHODS        59353\n",
       "RESULTS        57953\n",
       "CONCLUSIONS    27168\n",
       "BACKGROUND     21727\n",
       "OBJECTIVE      13839\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of labels in training data\n",
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "id": "J4oWMRCY3qf4",
    "outputId": "c4151091-bf70-4bd3-bb0b-766a27463471"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets check the length of different lines\n",
    "train_df.total_lines.plot.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uc1sYS1QFA9D"
   },
   "source": [
    "\n",
    "Get lists of sentencesÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FX-F0qOa3454",
    "outputId": "98199b07-a3a9-42a7-f3c3-45353d55c966"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180040, 30212, 30135)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert abstract text lines into lists \n",
    "train_sentences = train_df[\"text\"].tolist()\n",
    "val_sentences = val_df[\"text\"].tolist()\n",
    "test_sentences = test_df[\"text\"].tolist()\n",
    "len(train_sentences), len(val_sentences), len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3zkmZ2Ar6UOp",
    "outputId": "c40fbfed-ce27-43e6-8749-4e3dd858ce27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
       " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
       " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
       " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
       " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
       " 'these differences remained significant at @ weeks .']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View first 10 lines of training sentences\n",
    "train_sentences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5hV1SFEEsn8"
   },
   "source": [
    "## Make numeric labels (ML models require numeric labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jLYOYBM4FFpo",
    "outputId": "c1b081e6-8e74-4c39-e3b8-a050554ee213"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encode labels\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(sparse=False) # We want non-sparse matrix (sparse=True will compress all the zeros to save memory)\n",
    "train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1,1)) # here reshape(-1,1) means keep the 1st dimension same and add an extra one after that. eg for 5 it will become (5,1)\n",
    "val_labels_one_hot = one_hot_encoder.transform(val_df[\"target\"].to_numpy().reshape(-1,1)) # Here we do not fit_transform because it is already fit once on train labels\n",
    "test_labels_one_hot = one_hot_encoder.transform(test_df[\"target\"].to_numpy().reshape(-1,1))\n",
    "\n",
    "\n",
    "# Check what one hot encoderd labels look like\n",
    "train_labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TlbBrllJF8ST",
    "outputId": "41663cac-4187-4688-9169-816df6b119b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(180040, 5), dtype=float64, numpy=\n",
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.constant(train_labels_one_hot)\n",
    "#Tensorflow is incompitable with a sparse matrix. That is why we set sparse=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FsTLlxpoGrxz"
   },
   "source": [
    "### Label encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gks46YjMIc1t",
    "outputId": "0d75bf71-1be1-485e-d341-5007914801c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 2, ..., 4, 1, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract labels (\"target\" columns) and encode them into integers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
    "val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n",
    "test_labels_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())\n",
    "\n",
    "train_labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GgUMpmArMFSz",
    "outputId": "b548366c-801e-4ccb-988b-6b2631a16cbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get class names and number of classes from LabelEncoder instance \n",
    "num_classes = len(label_encoder.classes_) # To get the class names of the encoded vector\n",
    "class_names = label_encoder.classes_\n",
    "num_classes , class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHPVIODpMcty"
   },
   "source": [
    "## Creating a series of model experiments\n",
    "\n",
    "We're going to start with a baseline(TF-IDF Multinomial Naive Bayes classifier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVwuCtonNeGu"
   },
   "source": [
    "## Model 0: Getting a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "AbIkX6G_NhoO"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a pipeline\n",
    "model_0 = Pipeline([\n",
    "  (\"tf-idf\",TfidfVectorizer()),\n",
    "  (\"clf\", MultinomialNB())                  \n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(X=train_sentences,\n",
    "            y=train_labels_encoded);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b4_KhcF1O_L0",
    "outputId": "cbd3ebe1-0263-4668-c5ec-356e75759419"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7218323844829869"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the baseline model on the validation dataset\n",
    "model_0.score(X=val_sentences,\n",
    "              y=val_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G9RNdhn7P74c",
    "outputId": "60fd3854-ae0e-4a09-dbd5-4ee22772fe3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 3, ..., 4, 4, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60cyhonSQTCK"
   },
   "source": [
    "### Download helper function script\n",
    "\n",
    "Download helper functions used by Daniel Bourke\n",
    "https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UmGlH5odQwiM",
    "outputId": "17965de8-be58-448f-9eb8-dba988a1b25a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved under helper_functions.py\n"
     ]
    }
   ],
   "source": [
    "!python -m wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "FqFs2pRAQ7H0"
   },
   "outputs": [],
   "source": [
    "from helper_functions import calculate_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3V4E8cTRDtK",
    "outputId": "a856ec16-9945-40a2-820b-710691cf85c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 72.1832384482987,\n",
       " 'precision': 0.7186466952323352,\n",
       " 'recall': 0.7218323844829869,\n",
       " 'f1': 0.6989250353450294}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate baseline results\n",
    "baseline_results = calculate_results(y_true=val_labels_encoded,\n",
    "                                     y_pred=baseline_preds)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t16UGzs-R6TB"
   },
   "source": [
    "## Preparing our data (the text) for deep sequence models\n",
    "\n",
    "before we start building deeper models, we've got to create vectorization and embedding layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "dRKgsG4ySjKi"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wDrEHCCWTCac",
    "outputId": "5fcc1a6f-1ba0-42d0-bd86-1a049a0a931e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
       " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
       " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
       " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
       " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
       " 'these differences remained significant at @ weeks .']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l1llD0hNSukJ",
    "outputId": "3f56f2f0-cb0d-49bb-b32d-6f2b073f8074"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.338269273494777"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# How long is each sentence on average?\n",
    "\n",
    "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
    "avg_sent_len = np.mean(sent_lens)\n",
    "avg_sent_len # return average sentence length (in tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "xyuMfjKmTX4a",
    "outputId": "eace178d-b6c0-4fcd-8e99-4d7c1d1e6a48"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAXK0lEQVR4nO3df4xV553f8fdnIT/IDxywxxYLqJCabmtbjRMjSpsqakt2TZJqcSVbnZW2RhUSleVtk6pVC12p2f0Dya7adWu1RqLr1NhNgymbyGhTb0PxRqtKLmScOMHYoZ7EXnsWCrOx45CuzC7eb/+4z3TvjO/M3BkGZgbeL+nqnPs95znzPDrGnznn3LlPqgpJkn5mvjsgSVoYDARJEmAgSJIaA0GSBBgIkqRm6Xx3YLZuuOGGWrdu3Xx3Q5IWleeee+4Pq2qg17ZFGwjr1q1jaGhovrshSYtKkt+fbJu3jCRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEnAIv5L5fm0btfXZ9321Qc+N4c9kaS54xWCJAkwECRJjYEgSQIMBElSYyBIkoA+AyHJP05yMskLSb6S5P1JViY5kuTltlzRtf/uJMNJTiW5s6t+R5ITbdvDSdLq70vyZKsfS7JuzkcqSZrStIGQZDXwj4CNVXUbsAQYBHYBR6tqA3C0vSfJLW37rcBW4JEkS9rh9gI7gQ3ttbXVdwBvVtXNwEPAg3MyOklS3/q9ZbQUWJZkKfAB4DSwDdjftu8H7mrr24ADVXWhql4BhoFNSVYBy6vq2aoq4PEJbcaOdQjYMnb1IEm6MqYNhKr6A+BfA68BZ4C3quobwE1Vdabtcwa4sTVZDbzedYiRVlvd1ifWx7WpqovAW8D1E/uSZGeSoSRDo6Oj/Y5RktSHfm4ZraDzG/x64GeBDyb55ama9KjVFPWp2owvVO2rqo1VtXFgoOcc0ZKkWernltGngVeqarSq/gT4KvDXgLPtNhBtea7tPwKs7Wq/hs4tppG2PrE+rk27LXUd8MZsBiRJmp1+AuE1YHOSD7T7+luAl4DDwPa2z3bgqbZ+GBhsnxxaT+fh8fF2W+l8ks3tOPdOaDN2rLuBZ9pzBknSFTLtl9tV1bEkh4BvAxeB7wD7gA8BB5PsoBMa97T9TyY5CLzY9r+/qt5ph7sPeAxYBjzdXgCPAk8kGaZzZTA4J6OTJPWtr287raovAl+cUL5A52qh1/57gD096kPAbT3qb9MCRZI0P/xLZUkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqpg2EJD+X5Pmu10+SfCHJyiRHkrzcliu62uxOMpzkVJI7u+p3JDnRtj3cptKkTbf5ZKsfS7LusoxWkjSpaQOhqk5V1e1VdTtwB/BHwNeAXcDRqtoAHG3vSXILnSkwbwW2Ao8kWdIOtxfYSWee5Q1tO8AO4M2quhl4CHhwTkYnSerbTG8ZbQF+UFW/D2wD9rf6fuCutr4NOFBVF6rqFWAY2JRkFbC8qp6tqgIen9Bm7FiHgC1jVw+SpCtjpoEwCHylrd9UVWcA2vLGVl8NvN7VZqTVVrf1ifVxbarqIvAWcP3EH55kZ5KhJEOjo6Mz7LokaSp9B0KS9wK/CPzX6XbtUasp6lO1GV+o2ldVG6tq48DAwDTdkCTNxEyuED4DfLuqzrb3Z9ttINryXKuPAGu72q0BTrf6mh71cW2SLAWuA96YQd8kSZdoJoHwS/zZ7SKAw8D2tr4deKqrPtg+ObSezsPj4+220vkkm9vzgXsntBk71t3AM+05gyTpClnaz05JPgD8PPAPusoPAAeT7ABeA+4BqKqTSQ4CLwIXgfur6p3W5j7gMWAZ8HR7ATwKPJFkmM6VweAljEmSNAt9BUJV/RETHvJW1Y/ofOqo1/57gD096kPAbT3qb9MCRZI0P/xLZUkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSUCfgZDkI0kOJfl+kpeS/NUkK5McSfJyW67o2n93kuEkp5Lc2VW/I8mJtu3hNnMabXa1J1v9WJJ1cz5SSdKU+r1C+HfA71TVXwQ+BrwE7AKOVtUG4Gh7T5Jb6Mx4diuwFXgkyZJ2nL3ATjrTam5o2wF2AG9W1c3AQ8CDlzguSdIMTRsISZYDn6IzzSVV9cdV9WNgG7C/7bYfuKutbwMOVNWFqnoFGAY2JVkFLK+qZ9t8yY9PaDN2rEPAlrGrB0nSldHPFcJHgVHgPyX5TpLfTPJB4KaqOgPQlje2/VcDr3e1H2m11W19Yn1cm6q6CLzFhCk7AZLsTDKUZGh0dLTPIUqS+tFPICwFPgHsraqPA/+XdntoEr1+s68p6lO1GV+o2ldVG6tq48DAwNS9liTNSD+BMAKMVNWx9v4QnYA4224D0ZbnuvZf29V+DXC61df0qI9rk2QpcB3wxkwHI0mavWkDoar+D/B6kp9rpS3Ai8BhYHurbQeeauuHgcH2yaH1dB4eH2+3lc4n2dyeD9w7oc3Yse4GnmnPGSRJV8jSPvf7h8CXk7wX+CHw9+mEycEkO4DXgHsAqupkkoN0QuMicH9VvdOOcx/wGLAMeLq9oPPA+okkw3SuDAYvcVySpBnqKxCq6nlgY49NWybZfw+wp0d9CLitR/1tWqBIkuaHf6ksSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSU1fgZDk1SQnkjyfZKjVViY5kuTltlzRtf/uJMNJTiW5s6t+RzvOcJKH21SatOk2n2z1Y0nWzfE4JUnTmMkVwt+sqturamzmtF3A0araABxt70lyC50pMG8FtgKPJFnS2uwFdtKZZ3lD2w6wA3izqm4GHgIenP2QJEmzcSm3jLYB+9v6fuCurvqBqrpQVa8Aw8CmJKuA5VX1bFUV8PiENmPHOgRsGbt6kCRdGf0GQgHfSPJckp2tdlNVnQFoyxtbfTXwelfbkVZb3dYn1se1qaqLwFvA9RM7kWRnkqEkQ6Ojo312XZLUj6V97vfJqjqd5EbgSJLvT7Fvr9/sa4r6VG3GF6r2AfsANm7c+K7tkqTZ6+sKoapOt+U54GvAJuBsuw1EW55ru48Aa7uarwFOt/qaHvVxbZIsBa4D3pj5cCRJszVtICT5YJIPj60DvwC8ABwGtrfdtgNPtfXDwGD75NB6Og+Pj7fbSueTbG7PB+6d0GbsWHcDz7TnDJKkK6SfW0Y3AV9rz3iXAv+lqn4nybeAg0l2AK8B9wBU1ckkB4EXgYvA/VX1TjvWfcBjwDLg6fYCeBR4IskwnSuDwTkYmyRpBqYNhKr6IfCxHvUfAVsmabMH2NOjPgTc1qP+Ni1QJEnzw79UliQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqDARJEmAgSJKafqfQvKqs2/X1+e6CJC04XiFIkoAZBEKSJUm+k+S32/uVSY4kebktV3TtuzvJcJJTSe7sqt+R5ETb9nCbSpM23eaTrX4sybo5HKMkqQ8zuUL4PPBS1/tdwNGq2gAcbe9JcgudKTBvBbYCjyRZ0trsBXbSmWd5Q9sOsAN4s6puBh4CHpzVaCRJs9ZXICRZA3wO+M2u8jZgf1vfD9zVVT9QVReq6hVgGNiUZBWwvKqeraoCHp/QZuxYh4AtY1cPkqQro98rhH8L/DPgT7tqN1XVGYC2vLHVVwOvd+030mqr2/rE+rg2VXUReAu4fmInkuxMMpRkaHR0tM+uS5L6MW0gJPnbwLmqeq7PY/b6zb6mqE/VZnyhal9VbayqjQMDA312R5LUj34+dvpJ4BeTfBZ4P7A8yX8GziZZVVVn2u2gc23/EWBtV/s1wOlWX9Oj3t1mJMlS4DrgjVmOSZI0C9NeIVTV7qpaU1Xr6Dwsfqaqfhk4DGxvu20Hnmrrh4HB9smh9XQeHh9vt5XOJ9ncng/cO6HN2LHubj/jXVcIkqTL51L+MO0B4GCSHcBrwD0AVXUyyUHgReAicH9VvdPa3Ac8BiwDnm4vgEeBJ5IM07kyGLyEfkmSZmFGgVBV3wS+2dZ/BGyZZL89wJ4e9SHgth71t2mBIkmaH/6lsiQJMBAkSc01+eV28+lSvljv1Qc+N4c9kaTxvEKQJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKkxECRJgIEgSWr6mVP5/UmOJ/lukpNJfr3VVyY5kuTltlzR1WZ3kuEkp5Lc2VW/I8mJtu3hNnMabXa1J1v9WJJ1l2GskqQp9HOFcAH4W1X1MeB2YGuSzcAu4GhVbQCOtvckuYXOjGe3AluBR5IsacfaC+ykM63mhrYdYAfwZlXdDDwEPHjpQ5MkzUQ/cypXVf20vX1PexWwDdjf6vuBu9r6NuBAVV2oqleAYWBTklXA8qp6ts2X/PiENmPHOgRsGbt6kCRdGX09Q0iyJMnzwDngSFUdA26qqjMAbXlj23018HpX85FWW93WJ9bHtamqi8BbwPWzGI8kaZb6CoSqeqeqbgfW0Plt/13zInfp9Zt9TVGfqs34Ayc7kwwlGRodHZ2m15KkmZjRp4yq6sfAN+nc+z/bbgPRlufabiPA2q5ma4DTrb6mR31cmyRLgeuAN3r8/H1VtbGqNg4MDMyk65KkafTzKaOBJB9p68uATwPfBw4D29tu24Gn2vphYLB9cmg9nYfHx9ttpfNJNrfnA/dOaDN2rLuBZ9pzBknSFdLPnMqrgP3tk0I/Axysqt9O8ixwMMkO4DXgHoCqOpnkIPAicBG4v6reace6D3gMWAY83V4AjwJPJBmmc2UwOBeDkyT1b9pAqKrvAR/vUf8RsGWSNnuAPT3qQ8C7nj9U1du0QJEkzQ//UlmSBBgIkqTGQJAkAQaCJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSmn6m0Fyb5HeTvJTkZJLPt/rKJEeSvNyWK7ra7E4ynORUkju76nckOdG2Pdym0qRNt/lkqx9Lsu4yjFWSNIV+rhAuAv+kqv4SsBm4P8ktwC7gaFVtAI6297Rtg8CtwFbgkTb9JsBeYCedeZY3tO0AO4A3q+pm4CHgwTkYmyRpBqYNhKo6U1XfbuvngZeA1cA2YH/bbT9wV1vfBhyoqgtV9QowDGxKsgpYXlXPVlUBj09oM3asQ8CWsasHSdKVMaNnCO1WzseBY8BNVXUGOqEB3Nh2Ww283tVspNVWt/WJ9XFtquoi8BZwfY+fvzPJUJKh0dHRmXRdkjSNvgMhyYeA3wK+UFU/mWrXHrWaoj5Vm/GFqn1VtbGqNg4MDEzXZUnSDPQVCEneQycMvlxVX23ls+02EG15rtVHgLVdzdcAp1t9TY/6uDZJlgLXAW/MdDCSpNnr51NGAR4FXqqq3+jadBjY3ta3A0911QfbJ4fW03l4fLzdVjqfZHM75r0T2owd627gmfacQZJ0hSztY59PAn8POJHk+Vb7F8ADwMEkO4DXgHsAqupkkoPAi3Q+oXR/Vb3T2t0HPAYsA55uL+gEzhNJhulcGQxe2rAkSTM1bSBU1f+k9z1+gC2TtNkD7OlRHwJu61F/mxYokqT54V8qS5IAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVLTzxSaX0pyLskLXbWVSY4kebktV3Rt251kOMmpJHd21e9IcqJte7hNo0mbavPJVj+WZN0cj1GS1Id+ptB8DPj3wONdtV3A0ap6IMmu9v6fJ7mFzvSXtwI/C/yPJH+hTaG5F9gJ/C/gvwFb6UyhuQN4s6puTjIIPAj83bkY3NVm3a6vz7rtqw98bg57IulqNO0VQlX9Hp15jrttA/a39f3AXV31A1V1oapeAYaBTUlWAcur6tmqKjrhclePYx0CtoxdPUiSrpzZPkO4qarOALTlja2+Gni9a7+RVlvd1ifWx7WpqovAW8D1vX5okp1JhpIMjY6OzrLrkqRe5vqhcq/f7GuK+lRt3l2s2ldVG6tq48DAwCy7KEnqZbaBcLbdBqItz7X6CLC2a781wOlWX9OjPq5NkqXAdbz7FpUk6TKbbSAcBra39e3AU131wfbJofXABuB4u610Psnm9nzg3gltxo51N/BMe84gSbqCpv2UUZKvAH8DuCHJCPBF4AHgYJIdwGvAPQBVdTLJQeBF4CJwf/uEEcB9dD6xtIzOp4uebvVHgSeSDNO5Mhick5FJkmZk2kCoql+aZNOWSfbfA+zpUR8CbutRf5sWKJKk+eNfKkuSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJKA/ibI0VXAyXUkTccrBEkSYCBIkhoDQZIEGAiSpMZAkCQBfspIfbiUTyiBn1KSFosFc4WQZGuSU0mGk+ya7/5I0rVmQVwhJFkC/Afg54ER4FtJDlfVi/PbM80F/wZCWhwWRCAAm4DhqvohQJIDwDY6czPrGmaYSFfOQgmE1cDrXe9HgL8ycackO4Gd7e1Pk5yaxc+6AfjDWbRbqK6m8czpWPLgXB1p1q6mcwNX13iuprHAzMbz5ybbsFACIT1q9a5C1T5g3yX9oGSoqjZeyjEWkqtpPFfTWMDxLGRX01hg7sazUB4qjwBru96vAU7PU18k6Zq0UALhW8CGJOuTvBcYBA7Pc58k6ZqyIG4ZVdXFJL8C/HdgCfClqjp5mX7cJd1yWoCupvFcTWMBx7OQXU1jgTkaT6redateknQNWii3jCRJ88xAkCQB11ggLPavx0jyapITSZ5PMtRqK5McSfJyW66Y735OJsmXkpxL8kJXbdL+J9ndztWpJHfOT68nN8l4fi3JH7Rz9HySz3ZtW7DjSbI2ye8meSnJySSfb/VFd36mGMtiPTfvT3I8yXfbeH691ef+3FTVNfGi87D6B8BHgfcC3wVume9+zXAMrwI3TKj9K2BXW98FPDjf/Zyi/58CPgG8MF3/gVvaOXofsL6duyXzPYY+xvNrwD/tse+CHg+wCvhEW/8w8L9bnxfd+ZliLIv13AT4UFt/D3AM2Hw5zs21dIXw/78eo6r+GBj7eozFbhuwv63vB+6av65Mrap+D3hjQnmy/m8DDlTVhap6BRimcw4XjEnGM5kFPZ6qOlNV327r54GX6HyDwKI7P1OMZTILdiwA1fHT9vY97VVchnNzLQVCr6/HmOo/koWogG8kea59jQfATVV1Bjr/EIAb5613szNZ/xfz+fqVJN9rt5TGLuMXzXiSrAM+Tuc30UV9fiaMBRbpuUmyJMnzwDngSFVdlnNzLQVCX1+PscB9sqo+AXwGuD/Jp+a7Q5fRYj1fe4E/D9wOnAH+TasvivEk+RDwW8AXquonU+3ao7agxtNjLIv23FTVO1V1O51vcdiU5LYpdp/1eK6lQFj0X49RVafb8hzwNTqXgWeTrAJoy3Pz18NZmaz/i/J8VdXZ9o/3T4H/yJ9dqi/48SR5D53/gX65qr7ayovy/PQay2I+N2Oq6sfAN4GtXIZzcy0FwqL+eowkH0zy4bF14BeAF+iMYXvbbTvw1Pz0cNYm6/9hYDDJ+5KsBzYAx+ehfzMy9g+0+Tt0zhEs8PEkCfAo8FJV/UbXpkV3fiYbyyI+NwNJPtLWlwGfBr7P5Tg38/0E/Qo/rf8snU8c/AD41fnuzwz7/lE6nxz4LnByrP/A9cBR4OW2XDnffZ1iDF+hc6n+J3R+i9kxVf+BX23n6hTwmfnuf5/jeQI4AXyv/cNctRjGA/x1OrcVvgc8316fXYznZ4qxLNZz85eB77R+vwD8y1af83PjV1dIkoBr65aRJGkKBoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktT8P+b+741OzO/5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Whats the distribution look like\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(sent_lens, bins = 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wI5I8GvMT2tS",
    "outputId": "f971b129-6871-4701-a2b0-6436082a1b82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# How long of a sentence covers 95% of the lengths?\n",
    "output_seq_len = int(np.percentile(sent_lens, 95))\n",
    "output_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KJMpQSWMU0XK",
    "outputId": "e10ac45e-4f41-446b-bf4a-9b228d9dc5c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maximum sequence length is the training set\n",
    "max(sent_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vX8v6S68U_6F"
   },
   "source": [
    "## Create text vectorizer layer\n",
    "\n",
    "We want to make a layer which maps our texts from words to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Pkm7e7p6yqqv"
   },
   "outputs": [],
   "source": [
    "# How many words are in our vocabulary? (taken from 3.2 in https://arxiv.org/pdf/1710.06071.pdf)\n",
    "max_tokens = 68000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "Hh150r6ezM24"
   },
   "outputs": [],
   "source": [
    "# Create text vectorizer\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_tokens, # number of words in vocabulary\n",
    "                                    output_sequence_length=55) # desired output length of vectorized sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "kJvQKPfzz3ju"
   },
   "outputs": [],
   "source": [
    "# Adapt text vectorizer to training sentences\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ospvuJZ90L3K",
    "outputId": "d11f1939-16ad-472a-c8e1-358c2b7ce325"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      "after appliance placement , all patients were periodically educated to the oral hygiene procedures .\n",
      "\n",
      "Length of text: 15\n",
      "\n",
      "Vectorized text:\n",
      "[[   21  4726  1164    62    12     9 16767  8472     6     2   217  2619\n",
      "    705     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "# Test out text vectorizer om random sentences\n",
    "\n",
    "import random\n",
    "target_sentence = random.choice(train_sentences)\n",
    "print(f\"Text:\\n{target_sentence}\")\n",
    "print(f\"\\nLength of text: {len(target_sentence.split())}\")\n",
    "print(f\"\\nVectorized text:\\n{text_vectorizer([target_sentence])}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qwMm-APK0eyj",
    "outputId": "e39f87ee-9143-4673-a70b-cf2be659ab24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number od words in vocab: 64841\n",
      "Most common words in the vocab: ['', '[UNK]', 'the', 'and', 'of']\n",
      "Least common words in the vocab: ['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# How many words in our training vocabulary?\n",
    "\n",
    "rct_20k_text_vocab = text_vectorizer.get_vocabulary() # Gets all the 68k words\n",
    "print(f\"Number od words in vocab: {len(rct_20k_text_vocab)}\")\n",
    "print(f\"Most common words in the vocab: {rct_20k_text_vocab[:5]}\")\n",
    "print(f\"Least common words in the vocab: {rct_20k_text_vocab[-5:]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78WjQSdR16L9",
    "outputId": "3988fc3c-b588-4834-bdfa-b48adc84cf62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'text_vectorization',\n",
       " 'trainable': True,\n",
       " 'batch_input_shape': (None,),\n",
       " 'dtype': 'string',\n",
       " 'max_tokens': 68000,\n",
       " 'standardize': 'lower_and_strip_punctuation',\n",
       " 'split': 'whitespace',\n",
       " 'ngrams': None,\n",
       " 'output_mode': 'int',\n",
       " 'output_sequence_length': 55,\n",
       " 'pad_to_max_tokens': False}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the config of our text vectorizer\n",
    "text_vectorizer.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LdtzdMx2Nas"
   },
   "source": [
    "### Create custom text embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "Lt37mgJn4j2e"
   },
   "outputs": [],
   "source": [
    "#Create token embedding layer\n",
    "token_embed = layers.Embedding(input_dim=len(rct_20k_text_vocab), # length of vocabulary\n",
    "                               output_dim = 128,# Note: different embedding sizes result in drastically different numbers of parameters to train\n",
    "                               mask_zero=False,  # Use masking to handle variable sequence lengths (save space)[take the zeros or not]\n",
    "                               name=\"token_embedding\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TH1ygrDT55cd",
    "outputId": "a481770a-a75e-461b-94f1-1de6db638c36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence befor vectorization: \n",
      " after appliance placement , all patients were periodically educated to the oral hygiene procedures .\n",
      "\n",
      "Sentence after vectoriation: (before embedding): \n",
      " [[   21  4726  1164    62    12     9 16767  8472     6     2   217  2619\n",
      "    705     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]]\n",
      "sentence after embedding:\n",
      " [[[-0.04283118 -0.00387961 -0.01455583 ...  0.04825513 -0.00789366\n",
      "    0.00189775]\n",
      "  [ 0.00955675 -0.01191317  0.00780604 ... -0.01638478 -0.02591658\n",
      "    0.0444705 ]\n",
      "  [ 0.04580184  0.00879665 -0.00942345 ... -0.02971577 -0.02701733\n",
      "    0.02599433]\n",
      "  ...\n",
      "  [ 0.02408476  0.00877072  0.02966959 ...  0.02324628  0.01719328\n",
      "   -0.01311161]\n",
      "  [ 0.02408476  0.00877072  0.02966959 ...  0.02324628  0.01719328\n",
      "   -0.01311161]\n",
      "  [ 0.02408476  0.00877072  0.02966959 ...  0.02324628  0.01719328\n",
      "   -0.01311161]]]\n"
     ]
    }
   ],
   "source": [
    "# Show example embedding\n",
    "print(f\"Sentence befor vectorization: \\n {target_sentence}\\n\")\n",
    "vectorized_sentence = text_vectorizer([target_sentence])\n",
    "print(f\"Sentence after vectoriation: (before embedding): \\n {vectorized_sentence}\")\n",
    "embedded_sentence = token_embed(vectorized_sentence)\n",
    "print(f\"sentence after embedding:\\n {embedded_sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yar7qMH6u6x"
   },
   "source": [
    "## Create datasets (making sure our data loads as fast as possible)\n",
    "\n",
    "We're going to setup our data to run as fast as possible with the tensorflow tf.data API, many of the steps here are discussed at length in these two resources:\n",
    "* https://www.tensorflow.org/guide/data\n",
    "* https://www.tensorflow.org/guide/data_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RGUp5VRx7ddy",
    "outputId": "a3a78915-78a7-4a99-e1b9-7c5676254c37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((), (5,)), types: (tf.string, tf.float64)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TUrn our data into tensorflow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eIEtWu-N8720",
    "outputId": "36746c5f-a3b4-41d6-a05f-3e08cd5e7284"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None,), (None, 5)), types: (tf.string, tf.float64)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the TensorSliceDataset's and turn them into prefetched Datasets\n",
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2dFLTxW9TsG"
   },
   "source": [
    "## Model 1: Conv1D with token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "Re-0C_16A4vW"
   },
   "outputs": [],
   "source": [
    "# Creat 1D convolutional model to process sequences\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "text_vectors = text_vectorizer(inputs) # vectorize text inputs\n",
    "token_embedding = token_embed(text_vectors) # create embedding\n",
    "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(token_embedding)\n",
    "x = layers.GlobalAveragePooling1D()(x) # condense the output of our feature vector\n",
    "outputs = layers.Dense(num_classes, activation = \"softmax\")(x)\n",
    "model_1 = tf.keras.Model(inputs,outputs)\n",
    "\n",
    "# Compile\n",
    "model_1.compile(loss=\"categorical_crossentropy\", # if your labels are integer form (not one hot) use sparse_categorical_crossentropy\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dlKi51-jCaVf",
    "outputId": "037d4657-faef-48bf-bb4a-fef86151242c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "token_embedding (Embedding)  (None, 55, 128)           8299648   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 55, 64)            41024     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 8,340,997\n",
      "Trainable params: 8,340,997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gD9UHoLXC7By",
    "outputId": "98c08187-50bc-4e56-a505-0e4834454c30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 88s 156ms/step - loss: 0.9200 - accuracy: 0.6353 - val_loss: 0.6903 - val_accuracy: 0.7380\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 86s 153ms/step - loss: 0.6614 - accuracy: 0.7547 - val_loss: 0.6324 - val_accuracy: 0.7676\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 88s 157ms/step - loss: 0.6212 - accuracy: 0.7715 - val_loss: 0.5988 - val_accuracy: 0.7842\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history_model_1= model_1.fit(train_dataset,\n",
    "                             steps_per_epoch=int(0.1*len(train_dataset)), # only fit on 10% of batches for faster training time(562 instead of 5627(i.e 5800 that we set))\n",
    "                             epochs=3,\n",
    "                             validation_data=valid_dataset,\n",
    "                             validation_steps=int(0.1*len(valid_dataset))) # only validate on 10% of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QlQbw3O0EGHr",
    "outputId": "43eefb53-429b-4f60-813d-1b57a2c4ac96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 6s 6ms/step - loss: 0.6025 - accuracy: 0.7840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6025262475013733, 0.783993124961853]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Evaluate on whole validation dataset (we only validated on 10% of batches during training)\n",
    "model_1.evaluate(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MKrS4ph0EulG",
    "outputId": "0e772a42-6699-41ed-ce50-7c47eecd56b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.8761851e-01, 1.9758269e-01, 8.6081967e-02, 2.9121268e-01,\n",
       "        3.7504129e-02],\n",
       "       [5.0267291e-01, 2.1838549e-01, 1.3992302e-02, 2.5831172e-01,\n",
       "        6.6375672e-03],\n",
       "       [1.3508326e-01, 6.6259056e-03, 1.8941907e-03, 8.5633433e-01,\n",
       "        6.2400133e-05],\n",
       "       ...,\n",
       "       [1.6262543e-06, 4.5470477e-04, 4.6436756e-04, 1.9726738e-06,\n",
       "        9.9907732e-01],\n",
       "       [6.1252829e-02, 4.7542760e-01, 1.1595923e-01, 7.2276793e-02,\n",
       "        2.7508351e-01],\n",
       "       [1.5292081e-01, 6.9640863e-01, 3.7651952e-02, 3.9351862e-02,\n",
       "        7.3666729e-02]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions (our model outputs prediction probabilities for each class)\n",
    "model_1_pred_probs = model_1.predict(valid_dataset)\n",
    "model_1_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QeJhHtn0E740",
    "outputId": "097a6ea9-7a44-46ff-fce8-e2468aa51a67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 1, 1], dtype=int64)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert pred probs to classes\n",
    "model_1_preds = tf.argmax(model_1_pred_probs, axis=1)\n",
    "model_1_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DAW3Kqe_FBag",
    "outputId": "5d5ac2fc-8746-4dfc-c671-4936a817ae8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.39931153184165,\n",
       " 'precision': 0.7803886669473357,\n",
       " 'recall': 0.7839931153184165,\n",
       " 'f1': 0.7813729849803397}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate model_1 results\n",
    "model_1_results = calculate_results(val_labels_encoded,model_1_preds)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FSbC6tzUFoTH",
    "outputId": "ca47f4a0-a4ee-4bcf-8ea7-687aca5f12db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 72.1832384482987,\n",
       " 'precision': 0.7186466952323352,\n",
       " 'recall': 0.7218323844829869,\n",
       " 'f1': 0.6989250353450294}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgjdYZAdFsVt"
   },
   "source": [
    "## Model 2: Feature extraction with pretrained token embeddings\n",
    "\n",
    "Now lets use pretrained word embeddings from tensorflow hub, more specifically the universal sentence encoder:(USE): https://tfhub.dev/google/universal-sentence-encoder/4\n",
    "\n",
    "The paper originally used Glove embeddings, however, we're going going to stick with the later created USE pretrained embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "vVfqzUaOMHWy"
   },
   "outputs": [],
   "source": [
    "# Download pretrained Tensorflow Hub USE\n",
    "import tensorflow_hub as hub\n",
    "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                        trainable=False,\n",
    "                                        name=\"universal_sentence_encoder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_v7HNqK9Ohun",
    "outputId": "dbb9e787-1665-4962-989a-1682274fa2db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random training sentence:\n",
      "in patients who scored @ points or less in all scorings , intubation conditions were considered acceptable , however if any of the scores was greater than @ , intubation conditions were regarded unacceptable .\n",
      "\n",
      "Sentence after embedding:\n",
      "[-0.08068188 -0.00190032  0.02337556  0.02758141  0.05872887 -0.02905573\n",
      " -0.01498709 -0.0132398  -0.01699652  0.05631635  0.06265351 -0.00480677\n",
      " -0.00571957  0.06350227  0.01796289  0.00792038 -0.07877348  0.05257777\n",
      "  0.00156379  0.00074525  0.07446788  0.00411085 -0.05672675  0.01485376\n",
      " -0.02498941 -0.00951734 -0.02817356  0.07803362 -0.0241541   0.03827016] (truncated output)...\n",
      "\n",
      "Length of sentence embedding:\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "# Test out the pretrained embedding on a random sentence\n",
    "random_training_sentence = random.choice(train_sentences)\n",
    "print(f\"Random training sentence:\\n{random_training_sentence}\\n\")\n",
    "use_embedded_sentence = tf_hub_embedding_layer([random_training_sentence])\n",
    "print(f\"Sentence after embedding:\\n{use_embedded_sentence[0][:30]} (truncated output)...\\n\")\n",
    "print(f\"Length of sentence embedding:\\n{len(use_embedded_sentence[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-C-0GY5PXf7"
   },
   "source": [
    "### Building and fitting an NLP feature extraction model from TensorFlow Hub using pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "k6kopvzRPxBk"
   },
   "outputs": [],
   "source": [
    "# Define feature extractor model using TF Hub layer\n",
    "inputs = layers.Input(shape=[], dtype=tf.string)\n",
    "pretrained_embedding = tf_hub_embedding_layer(inputs) # tokenize text and create embedding\n",
    "x = layers.Dense(128, activation=\"relu\")(pretrained_embedding)  # add a fully connected layer on top of the embedding\n",
    "# Note: you could add more layers here if you wanted to\n",
    "outputs = layers.Dense(5, activation=\"softmax\")(x)  # create the output layer\n",
    "model_2 = tf.keras.Model(inputs,\n",
    "                         outputs, \n",
    "                         name=\"model_2_USE_feature_extractor\")\n",
    "\n",
    "# Compile the model\n",
    "model_2.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VUiNs6QXRA0j",
    "outputId": "c398ef07-2cff-4606-eb6e-ded681ea95af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_USE_feature_extractor\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None,)]                 0         \n",
      "_________________________________________________________________\n",
      "universal_sentence_encoder ( (None, 512)               256797824 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 256,864,133\n",
      "Trainable params: 66,309\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9v2RxpJdRCUj",
    "outputId": "21943e75-d17a-4f70-94f8-57cf8ed9748a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 9s 12ms/step - loss: 0.9156 - accuracy: 0.6511 - val_loss: 0.7947 - val_accuracy: 0.6912\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 6s 11ms/step - loss: 0.7661 - accuracy: 0.7031 - val_loss: 0.7523 - val_accuracy: 0.7048\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 7s 13ms/step - loss: 0.7480 - accuracy: 0.7144 - val_loss: 0.7362 - val_accuracy: 0.7128\n"
     ]
    }
   ],
   "source": [
    "# Fit model_2 to the data\n",
    "\n",
    "history_model_2 = model_2.fit(train_dataset,\n",
    "                              steps_per_epoch=int(0.1*len(train_dataset)),\n",
    "                              epochs=3,\n",
    "                              validation_data = valid_dataset,\n",
    "                              validation_steps=int(0.1*len(valid_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RRZ7dVEXRfuM",
    "outputId": "32566a6e-e20a-4422-8993-174aceb257a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 10s 10ms/step - loss: 0.7376 - accuracy: 0.7157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7376024723052979, 0.7157089710235596]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on whole validation dataset\n",
    "model_2.evaluate(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U9FvV09fRj0N",
    "outputId": "dfdccdf8-8ead-453f-9d5c-7a1014414725"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.3716559e-01, 3.4355944e-01, 2.4361440e-03, 2.1068339e-01,\n",
       "        6.1554406e-03],\n",
       "       [3.4803304e-01, 4.9245331e-01, 4.3972847e-03, 1.5279035e-01,\n",
       "        2.3259763e-03],\n",
       "       [2.5468490e-01, 1.3765882e-01, 1.8597938e-02, 5.5413634e-01,\n",
       "        3.4921966e-02],\n",
       "       ...,\n",
       "       [1.7355208e-03, 6.2870155e-03, 5.5199374e-02, 9.0668723e-04,\n",
       "        9.3587148e-01],\n",
       "       [4.4484404e-03, 4.5338266e-02, 1.9428274e-01, 1.4590293e-03,\n",
       "        7.5447148e-01],\n",
       "       [1.6555965e-01, 2.1437430e-01, 5.4760277e-01, 8.4202988e-03,\n",
       "        6.4042985e-02]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with feature extraction model\n",
    "model_2_pred_probs = model_2.predict(valid_dataset)\n",
    "model_2_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B4v0wGHTRsRT",
    "outputId": "cad4c34f-199d-4ff3-f061-4ae03c43c4b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 4, 2], dtype=int64)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the predictions with feature extraction model to classes\n",
    "model_2_preds = tf.argmax(model_2_pred_probs, axis=1)\n",
    "model_2_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "edaN1cT-R4ab",
    "outputId": "88d73283-d032-458b-fe7f-e25e2f60746d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 71.57089898053754,\n",
       " 'precision': 0.7160562889209549,\n",
       " 'recall': 0.7157089898053753,\n",
       " 'f1': 0.7127802294739073}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate results from TF Hub pretrained embeddings results on validation set\n",
    "model_2_results = calculate_results(y_true=val_labels_encoded,\n",
    "                                    y_pred=model_2_preds)\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__HHNVeESDq8"
   },
   "source": [
    "## Model 3: Conv1D with character embeddings\n",
    "\n",
    "The paper which we are replicating states that they used a combination of token and character-level embeddings\n",
    "\n",
    "Previously we used token-level embeddings but we'll need to do similar steps for characters if we want to use char-level embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hTTz40xTZof"
   },
   "source": [
    "### Creating character-level tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXPmkhwLUi7w",
    "outputId": "a3efcb65-534c-47c5-c214-db0cf82bf0a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "bbRsDvb2Uk8e"
   },
   "outputs": [],
   "source": [
    "# Make function to split sentences into characters\n",
    "def split_chars(text):\n",
    "  return \" \".join(list(text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lQyO6-FDU3DO",
    "outputId": "146bc53f-5f8a-471a-a9b2-b7ae115983b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t',\n",
       " 'o',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " 'v',\n",
       " 'e',\n",
       " 's',\n",
       " 't',\n",
       " 'i',\n",
       " 'g',\n",
       " 'a',\n",
       " 't',\n",
       " 'e',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'e',\n",
       " 'f',\n",
       " 'f',\n",
       " 'i',\n",
       " 'c',\n",
       " 'a',\n",
       " 'c',\n",
       " 'y',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " ' ',\n",
       " '@',\n",
       " ' ',\n",
       " 'w',\n",
       " 'e',\n",
       " 'e',\n",
       " 'k',\n",
       " 's',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " ' ',\n",
       " 'd',\n",
       " 'a',\n",
       " 'i',\n",
       " 'l',\n",
       " 'y',\n",
       " ' ',\n",
       " 'l',\n",
       " 'o',\n",
       " 'w',\n",
       " '-',\n",
       " 'd',\n",
       " 'o',\n",
       " 's',\n",
       " 'e',\n",
       " ' ',\n",
       " 'o',\n",
       " 'r',\n",
       " 'a',\n",
       " 'l',\n",
       " ' ',\n",
       " 'p',\n",
       " 'r',\n",
       " 'e',\n",
       " 'd',\n",
       " 'n',\n",
       " 'i',\n",
       " 's',\n",
       " 'o',\n",
       " 'l',\n",
       " 'o',\n",
       " 'n',\n",
       " 'e',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " ' ',\n",
       " 'i',\n",
       " 'm',\n",
       " 'p',\n",
       " 'r',\n",
       " 'o',\n",
       " 'v',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " ' ',\n",
       " 'p',\n",
       " 'a',\n",
       " 'i',\n",
       " 'n',\n",
       " ' ',\n",
       " ',',\n",
       " ' ',\n",
       " 'm',\n",
       " 'o',\n",
       " 'b',\n",
       " 'i',\n",
       " 'l',\n",
       " 'i',\n",
       " 't',\n",
       " 'y',\n",
       " ' ',\n",
       " ',',\n",
       " ' ',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " ' ',\n",
       " 's',\n",
       " 'y',\n",
       " 's',\n",
       " 't',\n",
       " 'e',\n",
       " 'm',\n",
       " 'i',\n",
       " 'c',\n",
       " ' ',\n",
       " 'l',\n",
       " 'o',\n",
       " 'w',\n",
       " '-',\n",
       " 'g',\n",
       " 'r',\n",
       " 'a',\n",
       " 'd',\n",
       " 'e',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " 'f',\n",
       " 'l',\n",
       " 'a',\n",
       " 'm',\n",
       " 'm',\n",
       " 'a',\n",
       " 't',\n",
       " 'i',\n",
       " 'o',\n",
       " 'n',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 's',\n",
       " 'h',\n",
       " 'o',\n",
       " 'r',\n",
       " 't',\n",
       " ' ',\n",
       " 't',\n",
       " 'e',\n",
       " 'r',\n",
       " 'm',\n",
       " ' ',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " ' ',\n",
       " 'w',\n",
       " 'h',\n",
       " 'e',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " 'r',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'e',\n",
       " 'f',\n",
       " 'f',\n",
       " 'e',\n",
       " 'c',\n",
       " 't',\n",
       " ' ',\n",
       " 'w',\n",
       " 'o',\n",
       " 'u',\n",
       " 'l',\n",
       " 'd',\n",
       " ' ',\n",
       " 'b',\n",
       " 'e',\n",
       " ' ',\n",
       " 's',\n",
       " 'u',\n",
       " 's',\n",
       " 't',\n",
       " 'a',\n",
       " 'i',\n",
       " 'n',\n",
       " 'e',\n",
       " 'd',\n",
       " ' ',\n",
       " 'a',\n",
       " 't',\n",
       " ' ',\n",
       " '@',\n",
       " ' ',\n",
       " 'w',\n",
       " 'e',\n",
       " 'e',\n",
       " 'k',\n",
       " 's',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " ' ',\n",
       " 'o',\n",
       " 'l',\n",
       " 'd',\n",
       " 'e',\n",
       " 'r',\n",
       " ' ',\n",
       " 'a',\n",
       " 'd',\n",
       " 'u',\n",
       " 'l',\n",
       " 't',\n",
       " 's',\n",
       " ' ',\n",
       " 'w',\n",
       " 'i',\n",
       " 't',\n",
       " 'h',\n",
       " ' ',\n",
       " 'm',\n",
       " 'o',\n",
       " 'd',\n",
       " 'e',\n",
       " 'r',\n",
       " 'a',\n",
       " 't',\n",
       " 'e',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " ' ',\n",
       " 's',\n",
       " 'e',\n",
       " 'v',\n",
       " 'e',\n",
       " 'r',\n",
       " 'e',\n",
       " ' ',\n",
       " 'k',\n",
       " 'n',\n",
       " 'e',\n",
       " 'e',\n",
       " ' ',\n",
       " 'o',\n",
       " 's',\n",
       " 't',\n",
       " 'e',\n",
       " 'o',\n",
       " 'a',\n",
       " 'r',\n",
       " 't',\n",
       " 'h',\n",
       " 'r',\n",
       " 'i',\n",
       " 't',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " '(',\n",
       " ' ',\n",
       " 'o',\n",
       " 'a',\n",
       " ' ',\n",
       " ')',\n",
       " ' ',\n",
       " '.']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_sentences[0]) # List of train_sentences[0] will giv us the characters of the 1st sentence(list of string gives characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "RvnXmq-YU9G2",
    "outputId": "4427c5ff-0b0d-4ef3-a54f-ba8d3e4b388b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(list(train_sentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "GnPRBBhYV39H",
    "outputId": "3123785b-510e-4eff-ceae-cbaa8385a16a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i n   p a t i e n t s   w h o   s c o r e d   @   p o i n t s   o r   l e s s   i n   a l l   s c o r i n g s   ,   i n t u b a t i o n   c o n d i t i o n s   w e r e   c o n s i d e r e d   a c c e p t a b l e   ,   h o w e v e r   i f   a n y   o f   t h e   s c o r e s   w a s   g r e a t e r   t h a n   @   ,   i n t u b a t i o n   c o n d i t i o n s   w e r e   r e g a r d e d   u n a c c e p t a b l e   .'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test splitting non-character-level sequence into characters\n",
    "split_chars(random_training_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g-NlBWIHWEs8",
    "outputId": "cb936e5a-8c9f-41b6-a8c0-10bba65cfdd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .\n"
     ]
    }
   ],
   "source": [
    "# Split sequence-level data splits into character-level data splits\n",
    "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
    "val_chars = [split_chars(sentence) for sentence in val_sentences]\n",
    "test_chars = [split_chars(sentence) for sentence in test_sentences]\n",
    "print(train_chars[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nOJz3DtwWXpo",
    "outputId": "fef851f1-1949-4e24-e2fc-160c2619e985"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149.3662574983337"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's the average character length?\n",
    "char_lens = [len(sentence) for sentence in train_sentences]\n",
    "mean_char_len = np.mean(char_lens)\n",
    "mean_char_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "bN8WZd3NW15H",
    "outputId": "aafe9e8e-106a-498d-c14a-e4fadada321e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.41175e+05, 3.71110e+04, 1.60000e+03, 1.27000e+02, 2.10000e+01,\n",
       "        5.00000e+00, 1.00000e+00]),\n",
       " array([1.00000000e+00, 1.98857143e+02, 3.96714286e+02, 5.94571429e+02,\n",
       "        7.92428571e+02, 9.90285714e+02, 1.18814286e+03, 1.38600000e+03]),\n",
       " <BarContainer object of 7 artists>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the distribution of our sequences at a character-level\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(char_lens, bins=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MgPB4-HhXhhF",
    "outputId": "ef3f665d-ea85-4903-ea3e-96928700aa27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Find what character length covers 95% of sequences\n",
    "output_seq_char_len = int(np.percentile(char_lens, 95))\n",
    "output_seq_char_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "U5uEgOAPYHOQ",
    "outputId": "21abc96f-f0ec-46dd-a1fb-900501199a22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all keyboard characters for char-level embedding\n",
    "import string\n",
    "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
    "alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "sUZ7Ry8cYq67"
   },
   "outputs": [],
   "source": [
    "# Create char-level token vectorizer instance\n",
    "NUM_CHAR_TOKENS = len(alphabet) + 2 # num characters in alphabet + space + OOV token(Out of vocabulary)\n",
    "char_vectorizer = TextVectorization(max_tokens=NUM_CHAR_TOKENS,  \n",
    "                                    output_sequence_length=output_seq_char_len,\n",
    "                                    standardize=\"lower_and_strip_punctuation\", # set standardization to 'None' if you want to keep punctuation\n",
    "                                    name=\"char_vectorizer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "psaN_diJZWI5"
   },
   "outputs": [],
   "source": [
    "# Adapt character vectorizer to training characters\n",
    "char_vectorizer.adapt(train_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eDrmpnykZurJ",
    "outputId": "d525b227-98e5-4a71-8a4e-7f57d7571664"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different characters in character vocab: 28\n",
      "5 most common characters: ['', '[UNK]', 'e', 't', 'i']\n",
      "5 least common characters: ['k', 'x', 'z', 'q', 'j']\n"
     ]
    }
   ],
   "source": [
    "# Char character vocab stats\n",
    "char_vocab = char_vectorizer.get_vocabulary()\n",
    "print(f\"Number of different characters in character vocab: {len(char_vocab)}\")\n",
    "print(f\"5 most common characters: {char_vocab[:5]}\")\n",
    "print(f\"5 least common characters: {char_vocab[-5:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SbZW0yFpaBFB",
    "outputId": "89bdfeca-b9b4-4e48-e010-e520771fad54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charified text:\n",
      " t w o   h o u r s   a f t e r   t r e a t m e n t   ,   t h e   s y m p t o m s   b e t w e e n   t h e   g r o u p s   s h o w e d   n o   d i f f e r e n c e   i n   m e a s u r e s   o f   n a u s e a   (   p   =   @   )   o r   d i z z i n e s s   (   p   =   @   )   .\n",
      "Length of random_train_chars: 108\n",
      "\n",
      "vectorized chars: \n",
      " [[ 3 20  7 13  7 16  8  9  5 17  3  2  8  3  8  2  5  3 15  2  6  3  3 13\n",
      "   2  9 19 15 14  3  7 15  9 22  2  3 20  2  2  6  3 13  2 18  8  7 16 14\n",
      "   9  9 13  7 20  2 10  6  7 10  4 17 17  2  8  2  6 11  2  4  6 15  2  5\n",
      "   9 16  8  2  9  7 17  6  5 16  9  2  5 14  7  8 10  4 25 25  4  6  2  9\n",
      "   9 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]]\n",
      "\n",
      "Length of vectorized chars: 290\n"
     ]
    }
   ],
   "source": [
    "# Test out character vectorizer\n",
    "\n",
    "random_train_chars = random.choice(train_chars)\n",
    "print(f\"Charified text:\\n {random_train_chars}\")\n",
    "print(f\"Length of random_train_chars: {len(random_train_chars.split())}\")\n",
    "vectorized_chars = char_vectorizer([random_train_chars])\n",
    "print(f\"\\nvectorized chars: \\n {vectorized_chars}\")\n",
    "print(f\"\\nLength of vectorized chars: {len(vectorized_chars[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAm-rf9pcAyO"
   },
   "source": [
    "## Creating a character-level embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "kkZqcjSGfivb"
   },
   "outputs": [],
   "source": [
    "# Create char embedding layer\n",
    "char_embed = layers.Embedding(input_dim=len(char_vocab),  # number of different characters\n",
    "                              output_dim = 25, # embedding dimension of each character (same as Figure 1 in https://arxiv.org/pdf/1612.05251.pdf)\n",
    "                              mask_zero=False, # don't use masks (this messes up model_5 if set to True)\n",
    "                              name='char_embed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AhzI2X_FgYyZ",
    "outputId": "7beb670e-fb44-4042-bb6b-20b4d68130bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charified text (before vectorization and embedding):\n",
      "t w o   h o u r s   a f t e r   t r e a t m e n t   ,   t h e   s y m p t o m s   b e t w e e n   t h e   g r o u p s   s h o w e d   n o   d i f f e r e n c e   i n   m e a s u r e s   o f   n a u s e a   (   p   =   @   )   o r   d i z z i n e s s   (   p   =   @   )   .\n",
      "\n",
      "Embedded chars (after vectorization and embedding):\n",
      "[[[-0.00467091  0.00628003  0.04586733 ... -0.0322768   0.03934177\n",
      "    0.01216657]\n",
      "  [-0.00671797  0.04997187 -0.02906092 ...  0.02658999  0.00814645\n",
      "    0.03427922]\n",
      "  [-0.023344   -0.0148584   0.01389381 ...  0.04507807  0.01872795\n",
      "   -0.03685634]\n",
      "  ...\n",
      "  [-0.02807024 -0.0195931   0.00395532 ... -0.03011898 -0.04269482\n",
      "   -0.02148722]\n",
      "  [-0.02807024 -0.0195931   0.00395532 ... -0.03011898 -0.04269482\n",
      "   -0.02148722]\n",
      "  [-0.02807024 -0.0195931   0.00395532 ... -0.03011898 -0.04269482\n",
      "   -0.02148722]]]\n",
      "\n",
      "Character embedding shape: (1, 290, 25)\n"
     ]
    }
   ],
   "source": [
    "# Test out character embedding layer\n",
    "print(f\"Charified text (before vectorization and embedding):\\n{random_train_chars}\\n\")\n",
    "char_embed_example = char_embed(char_vectorizer([random_train_chars]))\n",
    "print(f\"Embedded chars (after vectorization and embedding):\\n{char_embed_example}\\n\")\n",
    "print(f\"Character embedding shape: {char_embed_example.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTOuVMl5geTM"
   },
   "source": [
    "### Building a Conv1D model to fit on character embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "dNDUDFG_hjs-"
   },
   "outputs": [],
   "source": [
    "# Make Conv1D on chars only\n",
    "input = layers.Input(shape=(1,), dtype='string')\n",
    "char_vectors = char_vectorizer(inputs)\n",
    "char_embeddings = char_embed(char_vectors)\n",
    "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(char_embeddings)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model_3 = tf.keras.Model(inputs=inputs,\n",
    "                         outputs=outputs,\n",
    "                         name=\"model_3_conv1D_char_embedding\")\n",
    "\n",
    "# Compile model\n",
    "model_3.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jRkjcmcSi2re",
    "outputId": "4e989404-e8a0-4725-e50c-4d7b5832d18d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_conv1D_char_embedding\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None,)]                 0         \n",
      "_________________________________________________________________\n",
      "char_vectorizer (TextVectori (None, 290)               0         \n",
      "_________________________________________________________________\n",
      "char_embed (Embedding)       (None, 290, 25)           700       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 290, 64)           8064      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 9,089\n",
      "Trainable params: 9,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check the summary of conv1d_char_model\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8t4_GXPJjALp",
    "outputId": "a23684b0-582d-4404-db5f-89e49b76495e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None,), (None, 5)), types: (tf.string, tf.float64)>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create char level datasets\n",
    "train_char_dataset = tf.data.Dataset.from_tensor_slices((train_chars, train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_char_dataset = tf.data.Dataset.from_tensor_slices((val_chars, val_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_char_dataset = tf.data.Dataset.from_tensor_slices((test_chars, test_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_char_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "up2FENujkPsN",
    "outputId": "817eb325-e71a-47e4-97c4-1232ab9879b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 13s 23ms/step - loss: 1.2771 - accuracy: 0.4711 - val_loss: 1.0842 - val_accuracy: 0.5645\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 12s 22ms/step - loss: 1.0404 - accuracy: 0.5842 - val_loss: 0.9808 - val_accuracy: 0.6074\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 12s 22ms/step - loss: 0.9591 - accuracy: 0.6219 - val_loss: 0.9054 - val_accuracy: 0.6523\n"
     ]
    }
   ],
   "source": [
    "# Fit the model on chars only\n",
    "model_3_history = model_3.fit(train_char_dataset,\n",
    "                              steps_per_epoch=int(0.1*len(train_char_dataset)),\n",
    "                              epochs=3,\n",
    "                              validation_data=val_char_dataset,\n",
    "                              validation_steps=int(0.1*len(val_char_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JyO9pB4Mk-vN",
    "outputId": "67b7cdf8-61a9-41b1-a809-368741f15106"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 7s 8ms/step - loss: 0.9215 - accuracy: 0.6407: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9215273261070251, 0.6407057046890259]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model_3 on whole validation char dataset\n",
    "model_3.evaluate(val_char_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KvITwTjJlflT",
    "outputId": "92b50c2d-b603-49ff-b463-a399a8da61ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23093678, 0.31864288, 0.08925245, 0.33192608, 0.02924184],\n",
       "       [0.15710756, 0.61202097, 0.0357081 , 0.14005673, 0.05510662],\n",
       "       [0.13113311, 0.35683316, 0.26440406, 0.18060672, 0.06702292],\n",
       "       ...,\n",
       "       [0.03903359, 0.06499136, 0.13294525, 0.04319937, 0.71983045],\n",
       "       [0.02284054, 0.09680077, 0.19324464, 0.04007216, 0.64704186],\n",
       "       [0.5132434 , 0.38033295, 0.0305948 , 0.06303102, 0.01279782]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with character model only\n",
    "model_3_pred_probs=model_3.predict(val_char_dataset)\n",
    "model_3_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U0SNQKPplt7s",
    "outputId": "b03f7f09-07cd-41d4-9bdb-8fba1b6e9f5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([3, 1, 1, ..., 4, 4, 0], dtype=int64)>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert predictions to classes\n",
    "model_3_preds = tf.argmax(model_3_pred_probs,axis=1)\n",
    "model_3_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uJ7HAWwVmOcW",
    "outputId": "587bf5fd-12b6-4356-962f-def646aa1fe9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 64.07056798623064,\n",
       " 'precision': 0.6310953631390267,\n",
       " 'recall': 0.6407056798623064,\n",
       " 'f1': 0.6296923709068605}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Conv1D char only model results\n",
    "model_3_results = calculate_results(y_true=val_labels_encoded,\n",
    "                                        y_pred=model_3_preds)\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8A4QaOcmzbD"
   },
   "source": [
    "## Model 4: Combining pretrained token embeddings + character embeddings \n",
    "\n",
    "* Create a token-level model (similar to model_1)\n",
    "* Create a character-level model (similar to model_3 with a slight modification to reflect the paper)\n",
    "* Combine (using layers.Concatenate) the outputs of 1 and 2\n",
    "* Build a series of output layers on top of 3 similar to Figure 1 and section 4.2 of [Neural Networks for Joint Sentence Classification in Medical Paper Abstracts](https://arxiv.org/pdf/1612.05251.pdf)\n",
    "* Construct a model which takes token and character-level sequences as input and produces sequence label probabilities as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "iV4o71Rvnui3"
   },
   "outputs": [],
   "source": [
    "# 1. Setup token inputs/model\n",
    "token_inputs = layers.Input(shape=[], dtype=tf.string, name=\"token_input\")\n",
    "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
    "token_outputs = layers.Dense(128, activation = \"relu\")(token_embeddings)\n",
    "token_model = tf.keras.Model(inputs = token_inputs,\n",
    "                             outputs= token_outputs)\n",
    "\n",
    "# 2. Setup char inputs/model\n",
    "char_inputs = layers.Input(shape=(1,), dtype=tf.string, name=\"char_input\")\n",
    "char_vectors = char_vectorizer(char_inputs)\n",
    "char_embeddings = char_embed(char_vectors)\n",
    "char_bi_lstm = layers.Bidirectional(layers.LSTM(25))(char_embeddings) # bi-LSTM shown in Figure 1 of https://arxiv.org/pdf/1612.05251.pdf\n",
    "char_model = tf.keras.Model(inputs=char_inputs,\n",
    "                            outputs=char_bi_lstm)\n",
    "\n",
    "# 3. Concatenate token and char inputs (create hybrid token embedding)\n",
    "token_char_concat = layers.Concatenate(name=\"token_char_hybrid\")([token_model.output,\n",
    "                                                                  char_model.output])\n",
    "\n",
    "# 4. Create output layers - addition of dropout discussed in 4.2 of https://arxiv.org/pdf/1612.05251.pdf\n",
    "combined_dropout = layers.Dropout(0.5)(token_char_concat)\n",
    "combined_dense = layers.Dense(128, activation=\"relu\")(combined_dropout) # slightly different to Figure 1 due to different shapes of token/char embedding layers\n",
    "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
    "output_layer = layers.Dense(num_classes, activation=\"softmax\")(final_dropout)\n",
    "\n",
    "# 5. Construct model with char and token inputs\n",
    "model_4 = tf.keras.Model(inputs=[token_model.input, char_model.input],\n",
    "                         outputs=output_layer,\n",
    "                         name=\"model_4_token_and_char_embeddings\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MBXU1bBESpbC",
    "outputId": "86433da6-1f7b-47a1-c252-5a1181395e42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_token_and_char_embeddings\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_input (InputLayer)        [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_vectorizer (TextVectorizat (None, 290)          0           char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "universal_sentence_encoder (Ker (None, 512)          256797824   token_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "char_embed (Embedding)          (None, 290, 25)      700         char_vectorizer[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          65664       universal_sentence_encoder[1][0] \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 50)           10200       char_embed[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "token_char_hybrid (Concatenate) (None, 178)          0           dense_4[0][0]                    \n",
      "                                                                 bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 178)          0           token_char_hybrid[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          22912       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 5)            645         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 256,897,945\n",
      "Trainable params: 100,121\n",
      "Non-trainable params: 256,797,824\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get summary of token and character model\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 976
    },
    "id": "TwaGSkNVTOAv",
    "outputId": "16f5b187-932c-4923-f9c7-3d707c1d6d18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "# # Plot hybrid token and character model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model_4, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "b-ttXbqQvf5j"
   },
   "outputs": [],
   "source": [
    "# Compile token char model\n",
    "model_4.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer = tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozAUi0lV5Cxf"
   },
   "source": [
    "### Combining token and character data into a `tf.data` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "dxFBDRIw5Wqp"
   },
   "outputs": [],
   "source": [
    "# Combine chars and tokens into a dataset\n",
    "train_char_token_data = tf.data.Dataset.from_tensor_slices((train_sentences,train_chars)) # make data\n",
    "train_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot) # make labels\n",
    "train_char_token_dataset = tf.data.Dataset.zip((train_char_token_data,train_char_token_labels))\n",
    "\n",
    "# Prefetch and batch train data\n",
    "train_char_token_dataset = train_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Repeat same steps validation data\n",
    "val_char_token_data = tf.data.Dataset.from_tensor_slices((val_sentences,val_chars))\n",
    "val_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
    "val_char_token_dataset = tf.data.Dataset.zip((val_char_token_data, val_char_token_labels))\n",
    "val_char_token_dataset = val_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1DCAphdc7v72",
    "outputId": "9de13f34-71cd-4189-ed50-a00ba1c4192a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset shapes: (((None,), (None,)), (None, 5)), types: ((tf.string, tf.string), tf.float64)>,\n",
       " <PrefetchDataset shapes: (((None,), (None,)), (None, 5)), types: ((tf.string, tf.string), tf.float64)>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Check out training char and token embedding dataset\n",
    "train_char_token_dataset, val_char_token_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1lqpjFfgGgwa"
   },
   "source": [
    "Understanding tf.data.Dataset.from_tensor_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mFR7VMTIGoXl",
    "outputId": "4e9e26ca-1c97-4e58-ba86-a2c1aa6a03f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 10)\n",
      "<TensorSliceDataset shapes: ((3, 10), (5,)), types: (tf.int32, tf.int32)>\n",
      "\n",
      "(<tf.Tensor: shape=(3, 10), dtype=int32, numpy=\n",
      "array([[4, 9, 6, 0, 3, 9, 8, 4, 3, 6],\n",
      "       [8, 4, 3, 2, 5, 5, 0, 1, 3, 7],\n",
      "       [1, 7, 3, 2, 9, 6, 6, 3, 2, 4]])>, <tf.Tensor: shape=(5,), dtype=int32, numpy=array([4, 3, 3, 1, 7])>)\n",
      "\n",
      "(<tf.Tensor: shape=(3, 10), dtype=int32, numpy=\n",
      "array([[4, 6, 2, 8, 9, 0, 6, 8, 3, 0],\n",
      "       [3, 7, 1, 6, 3, 4, 8, 4, 4, 6],\n",
      "       [5, 3, 5, 8, 9, 2, 2, 2, 5, 6]])>, <tf.Tensor: shape=(5,), dtype=int32, numpy=array([9, 8, 5, 8, 3])>)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(np.random.randint(0,10, size=(2,3,10)))\n",
    "y = tf.constant(np.random.randint(0,10, size=(2,5)))\n",
    "print(x.shape)\n",
    "\n",
    "dataset_fts = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "print(dataset_fts)\n",
    "for _ in dataset_fts:\n",
    "    print()\n",
    "    print(_)\n",
    "\n",
    "    # So basically the dimension \"2\"(first dimension generally the batch size gets combined)\n",
    "    # (3,10) (5) and (3,10) (5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwGtEdoc7znH"
   },
   "source": [
    "### Fitting a model on token and character-level sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x86e_a8t8Oyg",
    "outputId": "92ca3310-c9be-4f9f-8ccd-78bc55bcee92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 96s 163ms/step - loss: 0.9837 - accuracy: 0.6078 - val_loss: 0.7873 - val_accuracy: 0.6968\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 86s 154ms/step - loss: 0.8096 - accuracy: 0.6908 - val_loss: 0.7223 - val_accuracy: 0.7264\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 88s 157ms/step - loss: 0.7796 - accuracy: 0.7025 - val_loss: 0.6956 - val_accuracy: 0.7384\n"
     ]
    }
   ],
   "source": [
    "# Fit the model on tokens and chars\n",
    "history_model_4 = model_4.fit(train_char_token_dataset,\n",
    "                              steps_per_epoch = int(0.1*len(train_char_token_dataset)),\n",
    "                              epochs=3,\n",
    "                              validation_data= val_char_token_dataset,\n",
    "                              validation_steps = int(0.1*len(val_char_token_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5YCBHejk-Yka",
    "outputId": "2a8eb55e-70c6-41d0-e99d-13f5db28e7ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 36s 38ms/step - loss: 0.6997 - accuracy: 0.73140s - loss: 0.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6996905207633972, 0.731431245803833]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on the whole validation dataset\n",
    "model_4.evaluate(val_char_token_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ug5J4GxkAuhI",
    "outputId": "7cecfc78-72c1-412c-ecd1-7d6c4af52378"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.4012836e-01, 3.3238903e-01, 5.0206888e-03, 2.1594033e-01,\n",
       "        6.5215761e-03],\n",
       "       [2.8811172e-01, 5.6679398e-01, 2.8508534e-03, 1.4048672e-01,\n",
       "        1.7567034e-03],\n",
       "       [2.8411865e-01, 1.2295221e-01, 4.4314865e-02, 5.1670474e-01,\n",
       "        3.1909548e-02],\n",
       "       ...,\n",
       "       [3.6423584e-04, 6.8955543e-03, 2.5080340e-02, 2.0403252e-04,\n",
       "        9.6745580e-01],\n",
       "       [7.4332561e-03, 6.2423356e-02, 1.7691566e-01, 3.8366714e-03,\n",
       "        7.4939108e-01],\n",
       "       [3.0140927e-01, 3.1565496e-01, 2.7053347e-01, 4.0080309e-02,\n",
       "        7.2321936e-02]], dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions using the token-character model hybrid\n",
    "model_4_pred_probs = model_4.predict(val_char_token_dataset)\n",
    "model_4_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e-o5uTsKB5SQ",
    "outputId": "a8a0ddc5-be38-4105-9be5-486a3d0ffbe8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 4, 1], dtype=int64)>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Turn prediction probabilities into prediction classes\n",
    "model_4_preds = tf.argmax(model_4_pred_probs, axis=1)\n",
    "model_4_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GTWmtGRfCDpG",
    "outputId": "3ec995d5-5aee-4d8a-881e-36cd98b1768b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 73.14312193830266,\n",
       " 'precision': 0.7330680347614803,\n",
       " 'recall': 0.7314312193830266,\n",
       " 'f1': 0.7282314208742288}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get results of token-char-hybrid model\n",
    "model_4_results = calculate_results(y_true=val_labels_encoded,\n",
    "                                    y_pred=model_4_preds)\n",
    "model_4_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "imEqpGVcCHe3",
    "outputId": "ac5e6390-9c3a-46ec-c9cf-187e04de53bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 72.1832384482987,\n",
       " 'precision': 0.7186466952323352,\n",
       " 'recall': 0.7218323844829869,\n",
       " 'f1': 0.6989250353450294}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yPy3QVzCMl2"
   },
   "source": [
    "## Model 5: Transfer Learning with pretrained token embeddings + character embeddings + positional embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "NU-VqdhuCQfv",
    "outputId": "0faa2bd0-bbf8-4e5a-bace-00ce506f2cba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>line_number</th>\n",
       "      <th>total_lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>a total of @ patients with primary knee oa wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>outcome measures included pain reduction and i...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>pain was assessed using the visual analog pain...</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>secondary outcome measures included the wester...</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      target                                               text  line_number  \\\n",
       "0  OBJECTIVE  to investigate the efficacy of @ weeks of dail...            0   \n",
       "1    METHODS  a total of @ patients with primary knee oa wer...            1   \n",
       "2    METHODS  outcome measures included pain reduction and i...            2   \n",
       "3    METHODS  pain was assessed using the visual analog pain...            3   \n",
       "4    METHODS  secondary outcome measures included the wester...            4   \n",
       "\n",
       "   total_lines  \n",
       "0           11  \n",
       "1           11  \n",
       "2           11  \n",
       "3           11  \n",
       "4           11  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KlhnOQkKUR5v"
   },
   "source": [
    "**Note**: Any engineered features used to train a model need to be available at test time. In our case, line numbers and total time are available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UowrAyDgVMPT"
   },
   "source": [
    "### Create positional embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fsi7iBXEVTTr",
    "outputId": "f595f22a-7cfe-496d-d7a5-1e0dedc11be5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     15000\n",
       "1     15000\n",
       "2     15000\n",
       "3     15000\n",
       "4     14992\n",
       "5     14949\n",
       "6     14758\n",
       "7     14279\n",
       "8     13346\n",
       "9     11981\n",
       "10    10041\n",
       "11     7892\n",
       "12     5853\n",
       "13     4152\n",
       "14     2835\n",
       "15     1861\n",
       "16     1188\n",
       "17      751\n",
       "18      462\n",
       "19      286\n",
       "20      162\n",
       "21      101\n",
       "22       66\n",
       "23       33\n",
       "24       22\n",
       "25       14\n",
       "26        7\n",
       "27        4\n",
       "28        3\n",
       "29        1\n",
       "30        1\n",
       "Name: line_number, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many different line numbers are there?\n",
    "train_df['line_number'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "Avi2Ql_-VhKk",
    "outputId": "0559161d-fe0a-4694-86d3-3cc4d028eb13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAD4CAYAAADGmmByAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAS6klEQVR4nO3df8yd5X3f8fcnNgskLQk/DLNsqEmx2hKUJsFhSOm2NLSLG9ZA2tA52hZvYnWXUSnRfsVE1ZJOsgTTWjK0hpWMKIb+AIe0wW2GNkKaZpUoxKS0BAjDGi64WNgJaYAugZp898e5nubw8PjxMZfPc54bv1/S0XOf77mvc65LN+aj677uc59UFZIkvVSvmHUHJEnDZpBIkroYJJKkLgaJJKmLQSJJ6rJy1h1YaqeeemqtW7du1t2QpEG55557vl5VqxZ67ZgLknXr1rFr165Zd0OSBiXJnx/qNU9tSZK6GCSSpC4GiSSpi0EiSepikEiSuhgkkqQuBokkqYtBIknqYpBIkrocc99s77Fu6+dm3YUlt+fKi2bdBUnLnDMSSVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHXxXlta1CzvL+Z9vqRhcEYiSepikEiSuhgkkqQuBokkqYtBIknqYpBIkroYJJKkLlMPkiQrkvxJkt9vz09OcnuSh9vfk8b2vSLJ7iQPJXnHWP28JPe1165JklZ/ZZKbW/2uJOumPR5J0gstxYzkA8CDY8+3AndU1XrgjvacJOcAm4DXAxuBjydZ0dpcC2wB1rfHxla/DPhmVZ0NXA1cNd2hSJLmm2qQJFkLXAT897HyxcD2tr0duGSsflNVPVtVjwC7gfOTrAZOrKo7q6qAG+a1mXuvW4AL52YrkqSlMe0ZyceAfw98d6x2elXtA2h/T2v1NcBjY/vtbbU1bXt+/QVtquog8C3glPmdSLIlya4kuw4cONA5JEnSuKkFSZJ/COyvqnsmbbJArRapL9bmhYWq66pqQ1VtWLVq1YTdkSRNYpo3bXwr8K4k7wSOB05M8hvAE0lWV9W+dtpqf9t/L3DGWPu1wOOtvnaB+nibvUlWAq8BnpzWgCRJLza1GUlVXVFVa6tqHaNF9C9U1T8BdgKb226bgVvb9k5gU7sS6yxGi+p3t9NfTye5oK1/vG9em7n3ek/7jBfNSCRJ0zOL28hfCexIchnwKHApQFXdn2QH8ABwELi8qp5vbd4PfAo4AbitPQCuB25MspvRTGTTUg1CkjSyJEFSVV8Evti2vwFceIj9tgHbFqjvAs5doP4dWhBJkmbDb7ZLkroYJJKkLgaJJKmLQSJJ6mKQSJK6GCSSpC4GiSSpi0EiSepikEiSuhgkkqQuBokkqYtBIknqYpBIkroYJJKkLgaJJKmLQSJJ6mKQSJK6GCSSpC4GiSSpi0EiSepikEiSuhgkkqQuBokkqYtBIknqYpBIkroYJJKkLgaJJKmLQSJJ6mKQSJK6GCSSpC4GiSSpi0EiSepikEiSuhgkkqQuBokkqYtBIknqYpBIkrpMLUiSHJ/k7iR/muT+JL/c6icnuT3Jw+3vSWNtrkiyO8lDSd4xVj8vyX3ttWuSpNVfmeTmVr8rybppjUeStLBpzkieBd5eVT8KvBHYmOQCYCtwR1WtB+5oz0lyDrAJeD2wEfh4khXtva4FtgDr22Njq18GfLOqzgauBq6a4ngkSQuYWpDUyDPt6XHtUcDFwPZW3w5c0rYvBm6qqmer6hFgN3B+ktXAiVV1Z1UVcMO8NnPvdQtw4dxsRZK0NFZO883bjOIe4Gzg16rqriSnV9U+gKral+S0tvsa4I/Hmu9ttb9u2/Prc20ea+91MMm3gFOAr8/rxxZGMxrOPPPMozdATdW6rZ+byefuufKimXyuNFRTXWyvquer6o3AWkazi3MX2X2hmUQtUl+szfx+XFdVG6pqw6pVqw7Ta0nSkViSq7aq6i+BLzJa23iina6i/d3fdtsLnDHWbC3weKuvXaD+gjZJVgKvAZ6cxhgkSQub5lVbq5K8tm2fAPwE8DVgJ7C57bYZuLVt7wQ2tSuxzmK0qH53Ow32dJIL2vrH++a1mXuv9wBfaOsokqQlMs01ktXA9rZO8gpgR1X9fpI7gR1JLgMeBS4FqKr7k+wAHgAOApdX1fPtvd4PfAo4AbitPQCuB25MspvRTGTTFMcjSVrA1IKkqv4MeNMC9W8AFx6izTZg2wL1XcCL1leq6ju0IJIkzcZEp7YOs0guSTqGTbpG8t/at9T/1dy6hyRJMGGQVNWPAf+Y0RVSu5L8VpKfnGrPJEmDMPFVW1X1MPBLwIeAvw9ck+RrSX5mWp2TJC1/k66RvCHJ1cCDwNuBn66qH2nbV0+xf5KkZW7Sq7b+K/AJ4MNV9e25YlU9nuSXptIzSdIgTBok7wS+Pfe9jiSvAI6vqv9XVTdOrXeSpGVv0jWSzzP6MuCcV7WaJOkYN2mQHD92S3ja9qum0yVJ0pBMGiR/leTNc0+SnAd8e5H9JUnHiEnXSD4IfDrJ3F13VwP/aCo9kiQNykRBUlVfTvLDwA8x+g2Qr1XVX0+1Z5KkQTiSmza+BVjX2rwpCVV1w1R6JUkajImCJMmNwA8C9wJzt3af+/10SdIxbNIZyQbgHH80SpI036RXbX0V+NvT7IgkaZgmnZGcCjyQ5G7g2bliVb1rKr2SJA3GpEHy0Wl2QpI0XJNe/vuHSX4AWF9Vn0/yKmDFdLsmSRqCSW8j//PALcCvt9Ia4LNT6pMkaUAmXWy/HHgr8BT8zY9cnTatTkmShmPSIHm2qp6be5JkJaPvkUiSjnGTBskfJvkwcEL7rfZPA783vW5JkoZi0iDZChwA7gN+AfgfjH6/XZJ0jJv0qq3vMvqp3U9MtzuSpKGZ9F5bj7DAmkhVve6o90iSNChHcq+tOccDlwInH/3uSJKGZqI1kqr6xtjjL6rqY8Dbp9s1SdIQTHpq681jT1/BaIby/VPpkSRpUCY9tfUrY9sHgT3Azx313kiSBmfSq7Z+fNodkSQN06Sntv71Yq9X1a8ene5IkobmSK7aeguwsz3/aeBLwGPT6JQkaTiO5Iet3lxVTwMk+Sjw6ar6F9PqmCRpGCa9RcqZwHNjz58D1h313kiSBmfSGcmNwN1JfpfRN9zfDdwwtV5JkgZj0qu2tiW5Dfi7rfTPq+pPptctSdJQTHpqC+BVwFNV9V+AvUnOWmznJGck+YMkDya5P8kHWv3kJLcnebj9PWmszRVJdid5KMk7xurnJbmvvXZNkrT6K5Pc3Op3JVl3JIOXJPWb9Kd2PwJ8CLiilY4DfuMwzQ4C/6aqfgS4ALg8yTmMbkl/R1WtB+5oz2mvbQJeD2wEPp5k7nfhrwW2AOvbY2OrXwZ8s6rOBq4GrppkPJKko2fSGcm7gXcBfwVQVY9zmFukVNW+qvpK234aeJDRb71fDGxvu20HLmnbFwM3VdWzVfUIsBs4P8lq4MSqurOqitHazHibufe6BbhwbrYiSVoakwbJc+1/4gWQ5NVH8iHtlNObgLuA06tqH4zChu/99vsaXvi9lL2ttqZtz6+/oE1VHQS+BZyywOdvSbIrya4DBw4cSdclSYcxaZDsSPLrwGuT/DzweSb8kask3wd8BvhgVT212K4L1GqR+mJtXliouq6qNlTVhlWrVh2uy5KkI3DYq7baqaKbgR8GngJ+CPgPVXX7BG2PYxQiv1lVv9PKTyRZXVX72mmr/a2+FzhjrPla4PFWX7tAfbzN3iQrgdcATx6uX5Kko+ewM5J2SuuzVXV7Vf27qvq3E4ZIgOuBB+fdi2snsLltbwZuHatvaldincVoUf3udvrr6SQXtPd837w2c+/1HuALrb+SpCUy6RcS/zjJW6rqy0fw3m8F/ilwX5J7W+3DwJWMTpVdBjzK6NcWqar7k+wAHmB0xdflVfV8a/d+4FPACcBt7QGjoLoxyW5GM5FNR9A/SdJRMGmQ/DjwL5PsYXTlVhhNVt5wqAZV9UcsvIYBcOEh2mwDti1Q3wWcu0D9O7QgkiTNxqJBkuTMqnoU+Kkl6o8kaWAONyP5LKO7/v55ks9U1c8uQZ8kSQNyuMX28VNTr5tmRyRJw3S4IKlDbEuSBBz+1NaPJnmK0czkhLYN31tsP3GqvZMkLXuLBklVrVjsdUmSjuQ28pIkvYhBIknqYpBIkroYJJKkLgaJJKmLQSJJ6mKQSJK6GCSSpC4GiSSpi0EiSepikEiSuhgkkqQuBokkqYtBIknqYpBIkroYJJKkLgaJJKmLQSJJ6mKQSJK6GCSSpC4GiSSpy8pZd0BabtZt/dxMPnfPlRfN5HOlXs5IJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV2mFiRJPplkf5KvjtVOTnJ7kofb35PGXrsiye4kDyV5x1j9vCT3tdeuSZJWf2WSm1v9riTrpjUWSdKhTXNG8ilg47zaVuCOqloP3NGek+QcYBPw+tbm40lWtDbXAluA9e0x956XAd+sqrOBq4GrpjYSSdIhTS1IqupLwJPzyhcD29v2duCSsfpNVfVsVT0C7AbOT7IaOLGq7qyqAm6Y12buvW4BLpybrUiSls5Sr5GcXlX7ANrf01p9DfDY2H57W21N255ff0GbqjoIfAs4ZaEPTbIlya4kuw4cOHCUhiJJguWz2L7QTKIWqS/W5sXFquuqakNVbVi1atVL7KIkaSFLHSRPtNNVtL/7W30vcMbYfmuBx1t97QL1F7RJshJ4DS8+lSZJmrKlDpKdwOa2vRm4day+qV2JdRajRfW72+mvp5Nc0NY/3jevzdx7vQf4QltHkSQtoan9sFWS3wbeBpyaZC/wEeBKYEeSy4BHgUsBqur+JDuAB4CDwOVV9Xx7q/czugLsBOC29gC4HrgxyW5GM5FN0xqLJOnQphYkVfXeQ7x04SH23wZsW6C+Czh3gfp3aEEkSZqd5bLYLkkaKINEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1GXlrDsgaWTd1s/N7LP3XHnRzD5bw+eMRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxbv/SprZnYe96/DLw+BnJEk2Jnkoye4kW2fdH0k61gw6SJKsAH4N+CngHOC9Sc6Zba8k6dgy9FNb5wO7q+r/AiS5CbgYeGCmvZI0EX/M6+Vh6EGyBnhs7Ple4O/M3ynJFmBLe/pMkode4uedCnz9JbZdbhzL8vNyGQcMYCy5auJdl/1YjkDPWH7gUC8MPUiyQK1eVKi6Driu+8OSXVW1ofd9lgPHsvy8XMYBjmW5mtZYBr1GwmgGcsbY87XA4zPqiyQdk4YeJF8G1ic5K8nfAjYBO2fcJ0k6pgz61FZVHUzyi8D/BFYAn6yq+6f4kd2nx5YRx7L8vFzGAY5luZrKWFL1oiUFSZImNvRTW5KkGTNIJEldDJIJvZxuxZJkT5L7ktybZNes+zOpJJ9Msj/JV8dqJye5PcnD7e9Js+zjpA4xlo8m+Yt2XO5N8s5Z9nFSSc5I8gdJHkxyf5IPtPqgjs0i4xjccUlyfJK7k/xpG8svt/pUjolrJBNot2L5P8BPMrrk+MvAe6tqkN+gT7IH2FBVg/qSVZK/BzwD3FBV57bafwKerKorW8CfVFUfmmU/J3GIsXwUeKaq/vMs+3akkqwGVlfVV5J8P3APcAnwzxjQsVlkHD/HwI5LkgCvrqpnkhwH/BHwAeBnmMIxcUYymb+5FUtVPQfM3YpFS6iqvgQ8Oa98MbC9bW9n9A9/2TvEWAapqvZV1Vfa9tPAg4zuOjGoY7PIOAanRp5pT49rj2JKx8QgmcxCt2IZ5H9gTQH/K8k97fYxQ3Z6Ve2D0f8IgNNm3J9ev5jkz9qpr2V9KmghSdYBbwLuYsDHZt44YIDHJcmKJPcC+4Hbq2pqx8QgmcxEt2IZkLdW1ZsZ3TX58naaRbN3LfCDwBuBfcCvzLQ3RyjJ9wGfAT5YVU/Nuj8v1QLjGORxqarnq+qNjO74cX6Sc6f1WQbJZF5Wt2Kpqsfb3/3A7zI6dTdUT7Rz23PnuPfPuD8vWVU90f7xfxf4BAM6Lu08/GeA36yq32nlwR2bhcYx5OMCUFV/CXwR2MiUjolBMpmXza1Ykry6LSSS5NXAPwC+unirZW0nsLltbwZunWFfusz9A2/ezUCOS1vYvR54sKp+deylQR2bQ41jiMclyaokr23bJwA/AXyNKR0Tr9qaULvk72N871Ys22bbo5cmyesYzUJgdIuc3xrKWJL8NvA2RrfCfgL4CPBZYAdwJvAocGlVLftF7EOM5W2MTp8UsAf4hbnz2ctZkh8D/jdwH/DdVv4wo/WFwRybRcbxXgZ2XJK8gdFi+gpGE4YdVfUfk5zCFI6JQSJJ6uKpLUlSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHX5/76gwPRfgZfqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the distribution of \"line_number\" column\n",
    "train_df.line_number.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kSTt3BbwV0hC",
    "outputId": "8e0a0f22-e2ce-4188-c5a7-1d82f2b63b45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10, 15), dtype=float32, numpy=\n",
       " array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
       "       dtype=float32)>,\n",
       " TensorShape([180040, 15]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use TensorFlow to create one-hot-encoded tensors of our \"line_number\" column \n",
    "train_line_numbers_one_hot = tf.one_hot(train_df['line_number'].to_numpy(), depth=15)\n",
    "val_line_numbers_one_hot = tf.one_hot(val_df[\"line_number\"].to_numpy(), depth=15)\n",
    "test_line_numbers_one_hot = tf.one_hot(test_df[\"line_number\"].to_numpy(), depth=15)\n",
    "train_line_numbers_one_hot[:10],train_line_numbers_one_hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBeegWujWgak"
   },
   "source": [
    "Now we've encoded our line numbers feature, lets do the same for our total lines feature.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7EQtqRnzXbhc",
    "outputId": "977dff09-aef4-4b2a-d8e2-18a0d0129b89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11    24468\n",
       "10    23639\n",
       "12    22113\n",
       "9     19400\n",
       "13    18438\n",
       "14    14610\n",
       "8     12285\n",
       "15    10768\n",
       "7      7464\n",
       "16     7429\n",
       "17     5202\n",
       "6      3353\n",
       "18     3344\n",
       "19     2480\n",
       "20     1281\n",
       "5      1146\n",
       "21      770\n",
       "22      759\n",
       "23      264\n",
       "4       215\n",
       "24      200\n",
       "25      182\n",
       "26       81\n",
       "28       58\n",
       "3        32\n",
       "30       31\n",
       "27       28\n",
       "Name: total_lines, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many different numbers of lines are there?\n",
    "train_df['total_lines'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "id": "GhAvZ79eXuZL",
    "outputId": "0fc0632f-12cb-41aa-e3ca-18a808b4cbcc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the distributions of total lines\n",
    "train_df.total_lines.plot.hist();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qlMAh5wkX-pZ",
    "outputId": "c1e134d0-5592-4e7b-ec48-93c1fd149f10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the coverage of a 'totat_lines' value of 20\n",
    "np.percentile(train_df.total_lines, 98) # a value of 20 covers 98% of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jvY-ODhgYYf2",
    "outputId": "9dfd7caa-9b26-44c4-a7ad-ff9c8bdfa985"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([180040, 20]),\n",
       " <tf.Tensor: shape=(10, 20), dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]], dtype=float32)>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use TensorFlow to create one-hot-encoded tensors of our \"total_lines\" column \n",
    "train_total_lines_one_hot = tf.one_hot(train_df[\"total_lines\"].to_numpy(), depth=20)\n",
    "val_total_lines_one_hot = tf.one_hot(val_df[\"total_lines\"].to_numpy(), depth=20)\n",
    "test_total_lines_one_hot = tf.one_hot(test_df[\"total_lines\"].to_numpy(), depth=20)\n",
    "\n",
    "# Check shape and samples of total lines one-hot tensor\n",
    "train_total_lines_one_hot.shape, train_total_lines_one_hot[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FI7SujRNYmSe"
   },
   "source": [
    "### Building a tribrid embedding model\n",
    "\n",
    "1. Create a token-level model (similar to model_1)\n",
    "2. Create a character-level model (similar to model_3 with a slight modification to reflect the paper)\n",
    "3. Create a \"line_number\" model (takes in one-hot-encoded \"line_number\" tensor and passes it through a non-linear layer)\n",
    "4. Create a \"total_lines\" model (takes in one-hot-encoded \"total_lines\" tensor and passes it through a non-linear layer)\n",
    "5. Combine (using layers.Concatenate) the outputs of 1 and 2 into a token-character-hybrid embedding and pass it series of output to Figure 1 and section 4.2 of Neural Networks for Joint Sentence Classification in Medical Paper Abstracts\n",
    "6. Combine (using layers.Concatenate) the outputs of 3, 4 and 5 into a token-character-positional tribrid embedding\n",
    "7. Create an output layer to accept the tribrid embedding and output predicted label probabilities\n",
    "8. Combine the inputs of 1, 2, 3, 4 and outputs of 7 into a `tf.keras.Model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "NrMGncxZH3Tv"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 1. Token inputs\n",
    "\n",
    "token_inputs = layers.Input(shape=[], dtype = \"string\", name = 'token_inputs')\n",
    "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
    "token_outputs = layers.Dense(128, activation= 'relu')(token_embeddings)\n",
    "token_model = tf.keras.Model(inputs=token_inputs,\n",
    "                             outputs=token_outputs)\n",
    "\n",
    "# 2. Char inputs\n",
    "char_inputs = layers.Input(shape=(1,), dtype=\"string\", name=\"char_inputs\")\n",
    "char_vectors = char_vectorizer(char_inputs)\n",
    "char_embeddings = char_embed(char_vectors)\n",
    "char_bi_lstm = layers.Bidirectional(layers.LSTM(24))(char_embeddings)\n",
    "char_model = tf.keras.Model(inputs=char_inputs,\n",
    "                            outputs=char_bi_lstm)\n",
    "\n",
    "# 3. Line numbers inputs\n",
    "line_number_inputs = layers.Input(shape=(15,), dtype=tf.int32, name = \"line_number_input\") # shape is 15 because train_line_numbers_one_hot[0].shape\n",
    "x= layers.Dense(32, activation=\"relu\")(line_number_inputs)\n",
    "line_number_model = tf.keras.Model(inputs=line_number_inputs,\n",
    "                                   outputs=x)\n",
    "\n",
    "# 4. Total lines inputs\n",
    "total_lines_inputs = layers.Input(shape=(20,), dtype=tf.int32, name=\"total_lines_input\") # shape is 20 because of train_total_lines_one_hot[0].shape\n",
    "y = layers.Dense(32, activation=\"relu\")(total_lines_inputs)\n",
    "total_line_model = tf.keras.Model(inputs=total_lines_inputs,\n",
    "                                  outputs=y)\n",
    "\n",
    "# 5. Combine token and char embeddings into a hybrid embedding\n",
    "combined_embeddings = layers.Concatenate(name=\"token_char_hybrid_embedding\")([token_model.output, \n",
    "                                                                              char_model.output])\n",
    "\n",
    "z = layers.Dense(256, activation=\"relu\")(combined_embeddings)\n",
    "z=layers.Dropout(0.5)(z)\n",
    "\n",
    "\n",
    "# 6. Combine positional embeddings with combined token and char embeddings into a tribrid embedding\n",
    "tribrid_embeddings = layers.Concatenate(name=\"token_char_positional_embedding\")([line_number_model.output,\n",
    "                                                                                total_line_model.output,\n",
    "                                                                                z])\n",
    "\n",
    "# 7. Create output layer\n",
    "output_layer= layers.Dense(5, activation=\"softmax\", name=\"output_layer\")(tribrid_embeddings)\n",
    "\n",
    "\n",
    "# 8. Put together model\n",
    "\n",
    "model_5 = tf.keras.Model(inputs=[line_number_model.input,\n",
    "                                 total_line_model.input,\n",
    "                                 token_model.input, \n",
    "                                 char_model.input],\n",
    "                         outputs=output_layer,\n",
    "                         name=\"tribrid_embedding_model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "POZug7hUOT26",
    "outputId": "5fb97c5b-bae1-4dbd-8759-735e93493c99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tribrid_embedding_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_inputs (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_inputs (InputLayer)       [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_vectorizer (TextVectorizat (None, 290)          0           char_inputs[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "universal_sentence_encoder (Ker (None, 512)          256797824   token_inputs[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "char_embed (Embedding)          (None, 290, 25)      700         char_vectorizer[2][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          65664       universal_sentence_encoder[2][0] \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 48)           9600        char_embed[2][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "token_char_hybrid_embedding (Co (None, 176)          0           dense_7[0][0]                    \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "line_number_input (InputLayer)  [(None, 15)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "total_lines_input (InputLayer)  [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 256)          45312       token_char_hybrid_embedding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 32)           512         line_number_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 32)           672         total_lines_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "token_char_positional_embedding (None, 320)          0           dense_8[0][0]                    \n",
      "                                                                 dense_9[0][0]                    \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 5)            1605        token_char_positional_embedding[0\n",
      "==================================================================================================\n",
      "Total params: 256,921,889\n",
      "Trainable params: 124,065\n",
      "Non-trainable params: 256,797,824\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get a summary of our token, char and positional embedding model\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 711
    },
    "id": "Rq74bDlsPC3A",
    "outputId": "ef5e85a0-d930-4be3-f5c8-00b3aacf620f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "# Plot the token, char, positional embedding model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model_5, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xw_EnEDS5nx"
   },
   "source": [
    "What is label smoothing?\n",
    "\n",
    "For example, if our model gets too confident on a single class (e.g. its prediction probability is really high), it may get stuck on that class and not consider other classes...\n",
    "\n",
    "Really confident: `[0.0, 0.0, 1.0, 0.0, 0.0]`\n",
    "\n",
    "what label smoothing does is it assigns some of the value from the highest pred prob to other classes, in turn, hopefully improving generalization: `[0.01, 0.01, 1.96, 0.01, 0.01]`\n",
    "\n",
    "for more on label smoothing see this: https://www.pyimagesearch.com/2019/12/30/label-smoothing-with-keras-tensorflow-and-deep-learning/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "vLN41JwGPhRg"
   },
   "outputs": [],
   "source": [
    "# Combine token,char and positional embedding model\n",
    "model_5.compile(loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2), # helps to prevent overfitting - add label smoothing (examples which are really confident get smoothed a little)\n",
    "                optimizer= tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8BQN0tKSFDi"
   },
   "source": [
    "### Create tribrid embedding datasets and fit tribrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dCEz-ulbYNx8",
    "outputId": "d897021b-951d-4c21-e523-e8609198e3e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset shapes: (((None, 15), (None, 20), (None,), (None,)), (None, 5)), types: ((tf.float32, tf.float32, tf.string, tf.string), tf.float64)>,\n",
       " <PrefetchDataset shapes: (((None, 15), (None, 20), (None,), (None,)), (None, 5)), types: ((tf.float32, tf.float32, tf.string, tf.string), tf.float64)>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create training and validation datasets (all four kinds of inputs)\n",
    "train_pos_char_token_data = tf.data.Dataset.from_tensor_slices((train_line_numbers_one_hot, # line numbers\n",
    "                                                                train_total_lines_one_hot, # total lines\n",
    "                                                                train_sentences, # train tokens\n",
    "                                                                train_chars)) # train chars\n",
    "\n",
    "\n",
    "train_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot) # train labels\n",
    "train_pos_char_token_dataset = tf.data.Dataset.zip((train_pos_char_token_data, train_pos_char_token_labels)) # combine data and labels\n",
    "train_pos_char_token_dataset = train_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # turn into batches and prefetch appropriately\n",
    "\n",
    "# Validation dataset\n",
    "val_pos_char_token_data = tf.data.Dataset.from_tensor_slices((val_line_numbers_one_hot, # line numbers\n",
    "                                                                val_total_lines_one_hot, # total lines\n",
    "                                                                val_sentences, # train tokens\n",
    "                                                                val_chars)) # train chars\n",
    "\n",
    "\n",
    "val_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot) # train labels\n",
    "val_pos_char_token_dataset = tf.data.Dataset.zip((val_pos_char_token_data, val_pos_char_token_labels)) # combine data and labels\n",
    "val_pos_char_token_dataset = val_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # turn into batches and prefetch appropriately\n",
    "\n",
    "# Check input shapes\n",
    "train_pos_char_token_dataset, val_pos_char_token_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nCVjKw6Habqa",
    "outputId": "659d4ae9-3454-452d-de97-0b03f4a8b0b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 101s 171ms/step - loss: 1.0981 - accuracy: 0.7188 - val_loss: 0.9848 - val_accuracy: 0.8055\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 94s 167ms/step - loss: 0.9715 - accuracy: 0.8138 - val_loss: 0.9537 - val_accuracy: 0.8198\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 103s 183ms/step - loss: 0.9555 - accuracy: 0.8199 - val_loss: 0.9392 - val_accuracy: 0.8298\n"
     ]
    }
   ],
   "source": [
    "# Fit the token, char and positional embedding model\n",
    "\n",
    "model_5_history = model_5.fit(train_pos_char_token_dataset,\n",
    "                              steps_per_epoch=int(0.1*len(train_pos_char_token_dataset)),\n",
    "                              epochs=3,\n",
    "                              validation_data = val_pos_char_token_dataset,\n",
    "                              validation_steps=int(0.1*len(val_pos_char_token_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3G1AdhTGbKlg",
    "outputId": "4d6c7841-2147-44a6-bbb0-d9c2f5405cc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 44s 44ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.53330266, 0.10463977, 0.0125126 , 0.3296364 , 0.01990859],\n",
       "       [0.587078  , 0.09288283, 0.04248013, 0.26786083, 0.00969817],\n",
       "       [0.2474112 , 0.12727763, 0.15043357, 0.4052627 , 0.0696149 ],\n",
       "       ...,\n",
       "       [0.03865271, 0.10332576, 0.03970177, 0.03194585, 0.786374  ],\n",
       "       [0.02835066, 0.2526036 , 0.07603782, 0.02480187, 0.6182061 ],\n",
       "       [0.24843569, 0.5585397 , 0.09546428, 0.04307275, 0.0544876 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with token-char-positional hybrid model\n",
    "\n",
    "model_5_pred_probs = model_5.predict(val_pos_char_token_dataset, verbose=1)\n",
    "model_5_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OXtdHgJybcYP",
    "outputId": "7aac7e0e-0788-4691-fe53-fd2c65bdef8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 4, 1], dtype=int64)>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn prediction probabilities into prediction classes\n",
    "model_5_preds = tf.argmax(model_5_pred_probs, axis=1)\n",
    "model_5_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ejDBKaZabxWJ",
    "outputId": "022cf357-a32c-4c62-845e-5ab8ceb58670"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 83.30795710313782,\n",
       " 'precision': 0.8320391184450099,\n",
       " 'recall': 0.8330795710313783,\n",
       " 'f1': 0.8318530126074698}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate results of token-char-positional hybrid model\n",
    "model_5_results = calculate_results(y_true=val_labels_encoded,\n",
    "                                    y_pred=model_5_preds)\n",
    "model_5_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xzv7lI4JbzNQ",
    "outputId": "0fcaf398-018d-4e3f-949e-5235db7a54dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 73.14312193830266,\n",
       " 'precision': 0.7330680347614803,\n",
       " 'recall': 0.7314312193830266,\n",
       " 'f1': 0.7282314208742288}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sE6CMdC3b9x2"
   },
   "source": [
    "## Compare model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "0M2RHVXOc60p",
    "outputId": "009d7b5f-4313-4a5a-c804-5eb3218685cd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>72.183238</td>\n",
       "      <td>0.718647</td>\n",
       "      <td>0.721832</td>\n",
       "      <td>0.698925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom_token_embed_conv1d</th>\n",
       "      <td>78.399312</td>\n",
       "      <td>0.780389</td>\n",
       "      <td>0.783993</td>\n",
       "      <td>0.781373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pretrained_token_embed</th>\n",
       "      <td>71.570899</td>\n",
       "      <td>0.716056</td>\n",
       "      <td>0.715709</td>\n",
       "      <td>0.712780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom_char_embed_conv1d</th>\n",
       "      <td>64.070568</td>\n",
       "      <td>0.631095</td>\n",
       "      <td>0.640706</td>\n",
       "      <td>0.629692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hybrid_char_token_embed</th>\n",
       "      <td>73.143122</td>\n",
       "      <td>0.733068</td>\n",
       "      <td>0.731431</td>\n",
       "      <td>0.728231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tribrid_pos_char_token_embed</th>\n",
       "      <td>83.307957</td>\n",
       "      <td>0.832039</td>\n",
       "      <td>0.833080</td>\n",
       "      <td>0.831853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               accuracy  precision    recall        f1\n",
       "baseline                      72.183238   0.718647  0.721832  0.698925\n",
       "custom_token_embed_conv1d     78.399312   0.780389  0.783993  0.781373\n",
       "pretrained_token_embed        71.570899   0.716056  0.715709  0.712780\n",
       "custom_char_embed_conv1d      64.070568   0.631095  0.640706  0.629692\n",
       "hybrid_char_token_embed       73.143122   0.733068  0.731431  0.728231\n",
       "tribrid_pos_char_token_embed  83.307957   0.832039  0.833080  0.831853"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine model results into a DataFrame\n",
    "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
    "                                  \"custom_token_embed_conv1d\": model_1_results,\n",
    "                                  \"pretrained_token_embed\": model_2_results,\n",
    "                                  \"custom_char_embed_conv1d\": model_3_results,\n",
    "                                  \"hybrid_char_token_embed\": model_4_results,\n",
    "                                  \"tribrid_pos_char_token_embed\": model_5_results})\n",
    "\n",
    "all_model_results = all_model_results.transpose()\n",
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "X8lBCstwdbVd"
   },
   "outputs": [],
   "source": [
    "# Reduce the accuracy to same scale as other metrics\n",
    "all_model_results['accuracy'] = all_model_results['accuracy']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "id": "GaUjcJFSd4QC",
    "outputId": "e90764e2-b1ff-45c7-a115-c6065e6de3ff"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot and compare all of the model results\n",
    "all_model_results.plot(kind=\"bar\",figsize=(10,7)).legend(bbox_to_anchor=(1.0,1.0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "id": "hS9f6FKSeRn0",
    "outputId": "b700aa49-8f07-4259-d24e-f66154537db2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sort model results by f1-score\n",
    "\n",
    "all_model_results.sort_values('f1', ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10,7));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zYj7KqPJfVFA"
   },
   "source": [
    "### Save and load best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i2Zod89WfkSm",
    "outputId": "c8145267-6233-4849-b73c-3e45e74ac638"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: skimlit_tribrid_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: skimlit_tribrid_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save best performing model to SavedModel format (default)\n",
    "model_5.save(\"skimlit_tribrid_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "IO950FoQfytD"
   },
   "outputs": [],
   "source": [
    "# Load in the best pperforming model\n",
    "loaded_model = tf.keras.models.load_model(\"skimlit_tribrid_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46g2cMPzgQuM",
    "outputId": "b4499d4d-869e-4f32-83e3-f9fdd249aec1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 0, 3, 2, 2, 4, 4, 4, 4, 1], dtype=int64)>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with the loaded model on the validation set\n",
    "loaded_pred_probs = loaded_model.predict(val_pos_char_token_dataset)\n",
    "loaded_preds = tf.argmax(loaded_pred_probs, axis=1)\n",
    "loaded_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uowucEvig42x",
    "outputId": "ef38dd3f-4531-433d-ab11-9a1eeea1b5cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 83.20203892493049,\n",
       " 'precision': 0.8305690283766348,\n",
       " 'recall': 0.8320203892493049,\n",
       " 'f1': 0.8307472187737373}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the results of our loaded model\n",
    "loaded_model_results = calculate_results(y_true=val_labels_encoded,\n",
    "                                         y_pred=loaded_preds)\n",
    "\n",
    "loaded_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TfbZV6EXgU95",
    "outputId": "cc97c7d3-64b4-4e81-ffce-3349933fa5f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 83.30795710313782,\n",
       " 'precision': 0.8320391184450099,\n",
       " 'recall': 0.8330795710313783,\n",
       " 'f1': 0.8318530126074698}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_results"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "09_SkimLit_nlp_milestone_project_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
